{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "mask_training.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "l9IQxr2jWaui",
        "Lp4s5Q5fdG_x",
        "LBR6LGJI2nbe",
        "kFpoV3E0-smW",
        "TqD0UEvTBQsD",
        "Uara-01_5NIB"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ea6fb45340da4e8dacbe2f6e842f7e52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_81bbabd7499b42e09a724dae2e41229f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_56314b73e1704ad9a58cca47b1d9dddc",
              "IPY_MODEL_7ea64759ee4e4d138fc57bcfed145e49",
              "IPY_MODEL_f73455ba24e54ac088b586bb47ae0d9d"
            ]
          }
        },
        "81bbabd7499b42e09a724dae2e41229f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "56314b73e1704ad9a58cca47b1d9dddc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_49dcff20a6404e26a3675486d1d8addc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e313a9e33228454296428162115f271e"
          }
        },
        "7ea64759ee4e4d138fc57bcfed145e49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_43d717f078bc4763be9eb390609e8f69",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 14698491,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 14698491,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7b674652fe844e5792301b9073b31918"
          }
        },
        "f73455ba24e54ac088b586bb47ae0d9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3a0a9ec1e9ff4af083f60deac042a8c3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 14.0M/14.0M [00:00&lt;00:00, 73.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f90b53b8fbaa4a109f4157448dbff730"
          }
        },
        "49dcff20a6404e26a3675486d1d8addc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e313a9e33228454296428162115f271e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "43d717f078bc4763be9eb390609e8f69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7b674652fe844e5792301b9073b31918": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a0a9ec1e9ff4af083f60deac042a8c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f90b53b8fbaa4a109f4157448dbff730": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joangog/object-detection/blob/main/mask_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIjcsMslUx9m"
      },
      "source": [
        "## Model training on mask dataset\n",
        "\n",
        "<!-- The following models will be trained with their respective hyperparameters:\n",
        "\n",
        "MASKD:\n",
        "\n",
        "| Model | Backbone | Batch Size | Epochs | LR Scheduler | Learning Rate | Optimizer | Momentum | Weight Decay |\n",
        "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
        "| YOLOv5s |  Custom | 16 | 100 | CycleLR | 0.01 | SGD | 0.937 | 0.0005\n",
        "| YOLOv5s |  Custom | 16 | 100 | CycleLR | 0.001 | Adam | 0.937 | 0.0005\n",
        "| YOLOv5m |  Custom | 16 | 100 | CycleLR | 0.01 | SGD | 0.937 | 0.0005\n",
        "| YOLOv5l |  Custom | 16 |  |  |  |\n",
        "| YOLOv3-tiny |  Darknet53 | 16 | 100 | CycleLR | 0.01 | SGD | 0.937 | 0.0005\n",
        "\n",
        "<br> -->\n",
        "\n",
        "\n",
        "PWMFD:\n",
        "\n",
        "| Model | Backbone | Batch Size | Epochs | LR Scheduler | Learning Rate | Optimizer | Momentum | Weight Decay |\n",
        "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
        "| YOLOv5s |  Custom | 32 | 100 | CycleLR | 0.01 | SGD | 0.937 | 0.0005\n",
        "| YOLOv3-tiny |  Darknet53 | 32 | 100 | CycleLR | 0.01 | SGD | 0.937 | 0.0005\n",
        "\n",
        "\n",
        "\n",
        "The following datasets can be used:\n",
        "*   MASKD (AICrowd)\n",
        "*   Properly Wearing Masked Face Detection Dataset \n",
        "\n",
        "<br>\n",
        "\n",
        "**Note: GPU Runtime needed (hosted or local)**\n",
        "\n",
        "*Example GPU: Tesla K80, 460.32.03, 11441 MiB*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X0kW-fHdG9R",
        "outputId": "0f6b4335-d962-416d-8fa7-aed54ac6c17d"
      },
      "source": [
        "# Show system specs\n",
        "!nvidia-smi --query-gpu=gpu_name,driver_version,memory.total --format=csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name, driver_version, memory.total [MiB]\n",
            "Tesla K80, 460.32.03, 11441 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVojvH9i8ua0"
      },
      "source": [
        "### Initialization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZHe4nxx8raL"
      },
      "source": [
        "# Parameters\n",
        "\n",
        "dataset_name = 'PWMFD'  # 'MASKD' or 'PWMFD'\n",
        "\n",
        "load_ckpt = False  # Flag for whether to load existing checkpoint or not\n",
        "load_cfg = False  # Flag for whether to load custom model configs or not\n",
        "pretrained = True  # (If load_ckpt == False) Flag for whether to start from COCO-pretrained model or randomly init weights\n",
        "data_augment = False  # Flag for whether to use albumentations data augmentations\n",
        "\n",
        "img_res = 320  # Image resolution (for YOLO models), try 640, 320 or 160\n",
        "num_workers = 2  #  Data loader workers\n",
        "batch_size = 32  # Data loader batch size (both training and inference)\n",
        "\n",
        "num_epochs = 50  # Epochs\n",
        "\n",
        "lr = 0.01  # Learning rate (initial)\n",
        "step_size = 3  # Learning rate step size (only for StepLR, YOLO uses CycleLR)\n",
        "gamma = 0.1  # Learning rate decay (only for StepLR)\n",
        "\n",
        "optimizer_type = 'sgd'  # 'sgd' or 'adam'\n",
        "momentum = 0.937  # Optimizer momentum (only for SGD optimizer)\n",
        "weight_decay = 0.0005  # Optimizer weight decay\n",
        "\n",
        "# Directories\n",
        "\n",
        "load_ckpt_path = '/content/drive/MyDrive/object-detection-checkpoints/PWMFD_yolov5s_1637236944_run/weights/last.pt'  # Loaded weights path\n",
        "save_ckpt_dir = '/content/drive/MyDrive/object-detection-checkpoints'  # Model save root directory (used when load_ckpt is False)\n",
        "load_cfg_path  = '/content/config/yolov5s-tr-exp.yaml'\n",
        "\n",
        "import os\n",
        "root_dir = os.getcwd()  # Root dir of project\n",
        "dataset_dir = os.path.join(root_dir,f'dataset_{dataset_name}')\n",
        "\n",
        "img_dir = os.path.join(dataset_dir,'images')\n",
        "val_img_dir = os.path.join(img_dir,'val_images')\n",
        "train_img_dir = os.path.join(img_dir,'train_images')\n",
        "\n",
        "label_dir = os.path.join(dataset_dir,'labels')\n",
        "val_label_dir = os.path.join(label_dir,'val_images')\n",
        "train_label_dir = os.path.join(label_dir,'train_images')\n",
        "\n",
        "ann_dir = os.path.join(dataset_dir,'annotations')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9IQxr2jWaui"
      },
      "source": [
        "### Get requirements\n",
        "*Note: Restart runtime after installation*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gWOqjlQQdaP",
        "outputId": "e0901b12-66f4-4204-bd57-24ba3c3a54ba"
      },
      "source": [
        "# Clone asset files\n",
        "!cd {root_dir}\n",
        "!git clone https://github.com/joangog/object-detection-assets\n",
        "!mv -n {os.path.join(root_dir,'object-detection-assets','scripts')} ./\n",
        "!mv -n {os.path.join(root_dir,'object-detection-assets','config')} ./\n",
        "!mv -n {os.path.join(root_dir,'object-detection-assets','requirements.txt')} ./\n",
        "!rm -rf {os.path.join(root_dir,'object-detection-assets')}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'object-detection-assets'...\n",
            "remote: Enumerating objects: 175, done.\u001b[K\n",
            "remote: Counting objects: 100% (175/175), done.\u001b[K\n",
            "remote: Compressing objects: 100% (130/130), done.\u001b[K\n",
            "remote: Total 175 (delta 67), reused 139 (delta 34), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (175/175), 35.59 KiB | 1.69 MiB/s, done.\n",
            "Resolving deltas: 100% (67/67), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVa0AxzKlSyv",
        "outputId": "fe6a0f5e-0823-4be0-c7a2-dafe44359ab5"
      },
      "source": [
        "# Install packages\n",
        "!cd {root_dir}\n",
        "if data_augment:\n",
        "  !pip install albumentations==1.0.3\n",
        "else:\n",
        "  !pip install albumentations==0.1.12\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: albumentations==0.1.12 in /usr/local/lib/python3.7/dist-packages (0.1.12)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from albumentations==0.1.12) (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.1.12) (1.19.5)\n",
            "Collecting imgaug<0.2.7,>=0.2.5\n",
            "  Downloading imgaug-0.2.6.tar.gz (631 kB)\n",
            "\u001b[K     |████████████████████████████████| 631 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==0.1.12) (1.4.1)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations==0.1.12) (0.18.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations==0.1.12) (1.15.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.1.12) (1.2.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.1.12) (2021.11.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.1.12) (2.4.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.1.12) (7.1.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.1.12) (3.2.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.1.12) (2.6.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.1.12) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.1.12) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.1.12) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.1.12) (1.3.2)\n",
            "Building wheels for collected packages: imgaug\n",
            "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imgaug: filename=imgaug-0.2.6-py3-none-any.whl size=654020 sha256=7e017afbf75d6334849c353cf204b2b461a5cc8566dc8a832e68411851bcefb2\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/72/98/3ebfdba1069a9a8eaaa7ae7265cfd67d63ef0197aaee2e5f9c\n",
            "Successfully built imgaug\n",
            "Installing collected packages: imgaug\n",
            "  Attempting uninstall: imgaug\n",
            "    Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "Successfully installed imgaug-0.2.6\n",
            "Collecting git+https://github.com/googlecolab/colabtools.git (from -r requirements.txt (line 31))\n",
            "  Cloning https://github.com/googlecolab/colabtools.git to /tmp/pip-req-build-zgmgd9aw\n",
            "  Running command git clone -q https://github.com/googlecolab/colabtools.git /tmp/pip-req-build-zgmgd9aw\n",
            "Requirement already satisfied: gdown==3.6.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (3.6.4)\n",
            "Requirement already satisfied: google==2.0.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (2.0.3)\n",
            "Requirement already satisfied: ipykernel==4.10.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (4.10.1)\n",
            "Requirement already satisfied: ipython==5.5.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (5.5.0)\n",
            "Requirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (1.0.0)\n",
            "Requirement already satisfied: matplotlib==3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (3.2.2)\n",
            "Requirement already satisfied: notebook==5.3.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (5.3.1)\n",
            "Requirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.19.5)\n",
            "Requirement already satisfied: opencv-python==4.1.2.30 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (4.1.2.30)\n",
            "Requirement already satisfied: pandas==1.1.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (1.1.5)\n",
            "Requirement already satisfied: Pillow==7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (7.1.2)\n",
            "Requirement already satisfied: pip-tools==6.2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (6.2.0)\n",
            "Requirement already satisfied: pycocotools==2.0.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 15)) (2.0.2)\n",
            "Collecting scikit-image==0.16.2\n",
            "  Downloading scikit_image-0.16.2-cp37-cp37m-manylinux1_x86_64.whl (26.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.5 MB 46 kB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.22.2.post1\n",
            "  Downloading scikit_learn-0.22.2.post1-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 32.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 18)) (1.4.1)\n",
            "Requirement already satisfied: sklearn==0.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 19)) (0.0)\n",
            "Requirement already satisfied: sklearn-pandas==1.8.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (1.8.0)\n",
            "Collecting tensorboard==2.6.0\n",
            "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 38.5 MB/s \n",
            "\u001b[?25hCollecting tensorflow==2.6.0\n",
            "  Downloading tensorflow-2.6.0-cp37-cp37m-manylinux2010_x86_64.whl (458.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 458.3 MB 11 kB/s \n",
            "\u001b[?25hCollecting torch==1.9.0\n",
            "  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 2.8 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.10.0\n",
            "  Downloading torchvision-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (22.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.1 MB 11.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tornado==5.1.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 25)) (5.1.1)\n",
            "Collecting traitlets==5.1.0\n",
            "  Downloading traitlets-5.1.0-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 10.4 MB/s \n",
            "\u001b[?25hCollecting textwrap3\n",
            "  Downloading textwrap3-0.9.2-py2.py3-none-any.whl (12 kB)\n",
            "Collecting ptflops\n",
            "  Downloading ptflops-0.6.6.tar.gz (11 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 30)) (5.4.8)\n",
            "Requirement already satisfied: astor~=0.8.1 in /usr/local/lib/python3.7/dist-packages (from google-colab==1.0.0->-r requirements.txt (line 31)) (0.8.1)\n",
            "Requirement already satisfied: google-auth>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from google-colab==1.0.0->-r requirements.txt (line 31)) (1.35.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from google-colab==1.0.0->-r requirements.txt (line 31)) (1.15.0)\n",
            "Requirement already satisfied: portpicker~=1.3.1 in /usr/local/lib/python3.7/dist-packages (from google-colab==1.0.0->-r requirements.txt (line 31)) (1.3.9)\n",
            "Requirement already satisfied: requests~=2.23.0 in /usr/local/lib/python3.7/dist-packages (from google-colab==1.0.0->-r requirements.txt (line 31)) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown==3.6.4->-r requirements.txt (line 3)) (4.62.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from google==2.0.3->-r requirements.txt (line 4)) (4.6.3)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel==4.10.1->-r requirements.txt (line 5)) (5.3.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython==5.5.0->-r requirements.txt (line 6)) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython==5.5.0->-r requirements.txt (line 6)) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython==5.5.0->-r requirements.txt (line 6)) (0.8.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython==5.5.0->-r requirements.txt (line 6)) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython==5.5.0->-r requirements.txt (line 6)) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython==5.5.0->-r requirements.txt (line 6)) (57.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython==5.5.0->-r requirements.txt (line 6)) (2.6.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->-r requirements.txt (line 7)) (7.6.5)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->-r requirements.txt (line 7)) (5.6.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->-r requirements.txt (line 7)) (5.2.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->-r requirements.txt (line 7)) (5.2.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2->-r requirements.txt (line 8)) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2->-r requirements.txt (line 8)) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2->-r requirements.txt (line 8)) (3.0.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.2->-r requirements.txt (line 8)) (0.11.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook==5.3.1->-r requirements.txt (line 9)) (5.1.3)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook==5.3.1->-r requirements.txt (line 9)) (0.12.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook==5.3.1->-r requirements.txt (line 9)) (1.8.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook==5.3.1->-r requirements.txt (line 9)) (2.11.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook==5.3.1->-r requirements.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook==5.3.1->-r requirements.txt (line 9)) (4.9.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.5->-r requirements.txt (line 12)) (2018.9)\n",
            "Requirement already satisfied: pip>=20.3 in /usr/local/lib/python3.7/dist-packages (from pip-tools==6.2.0->-r requirements.txt (line 14)) (21.1.3)\n",
            "Requirement already satisfied: pep517 in /usr/local/lib/python3.7/dist-packages (from pip-tools==6.2.0->-r requirements.txt (line 14)) (0.12.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from pip-tools==6.2.0->-r requirements.txt (line 14)) (0.37.0)\n",
            "Requirement already satisfied: click>=7 in /usr/local/lib/python3.7/dist-packages (from pip-tools==6.2.0->-r requirements.txt (line 14)) (7.1.2)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0.2->-r requirements.txt (line 15)) (0.29.24)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2->-r requirements.txt (line 16)) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2->-r requirements.txt (line 16)) (1.2.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.16.2->-r requirements.txt (line 16)) (2.6.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22.2.post1->-r requirements.txt (line 17)) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.6.0->-r requirements.txt (line 21)) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.6.0->-r requirements.txt (line 21)) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.6.0->-r requirements.txt (line 21)) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.6.0->-r requirements.txt (line 21)) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.6.0->-r requirements.txt (line 21)) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.6.0->-r requirements.txt (line 21)) (1.42.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.6.0->-r requirements.txt (line 21)) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard==2.6.0->-r requirements.txt (line 21)) (0.12.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0->-r requirements.txt (line 22)) (3.1.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0->-r requirements.txt (line 22)) (3.3.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0->-r requirements.txt (line 22)) (0.4.0)\n",
            "Collecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0->-r requirements.txt (line 22)) (2.7.0)\n",
            "Collecting clang~=5.0\n",
            "  Downloading clang-5.0.tar.gz (30 kB)\n",
            "Collecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0->-r requirements.txt (line 22)) (1.1.2)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0->-r requirements.txt (line 22)) (0.2.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0->-r requirements.txt (line 22)) (1.1.0)\n",
            "Collecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0->-r requirements.txt (line 22)) (2.7.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.6.0->-r requirements.txt (line 22)) (1.6.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.17.2->google-colab==1.0.0->-r requirements.txt (line 31)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.17.2->google-colab==1.0.0->-r requirements.txt (line 31)) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.17.2->google-colab==1.0.0->-r requirements.txt (line 31)) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.6.0->-r requirements.txt (line 21)) (1.3.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow==2.6.0->-r requirements.txt (line 22)) (1.5.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel==4.10.1->-r requirements.txt (line 5)) (22.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard==2.6.0->-r requirements.txt (line 21)) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard==2.6.0->-r requirements.txt (line 21)) (3.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython==5.5.0->-r requirements.txt (line 6)) (0.2.5)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.17.2->google-colab==1.0.0->-r requirements.txt (line 31)) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests~=2.23.0->google-colab==1.0.0->-r requirements.txt (line 31)) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests~=2.23.0->google-colab==1.0.0->-r requirements.txt (line 31)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests~=2.23.0->google-colab==1.0.0->-r requirements.txt (line 31)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests~=2.23.0->google-colab==1.0.0->-r requirements.txt (line 31)) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.6.0->-r requirements.txt (line 21)) (3.1.1)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook==5.3.1->-r requirements.txt (line 9)) (0.7.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->-r requirements.txt (line 7)) (1.0.2)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->-r requirements.txt (line 7)) (3.5.2)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook==5.3.1->-r requirements.txt (line 9)) (2.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook==5.3.1->-r requirements.txt (line 9)) (2.0.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 7)) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 7)) (4.1.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 7)) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 7)) (0.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 7)) (1.5.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 7)) (0.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter==1.0.0->-r requirements.txt (line 7)) (21.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter==1.0.0->-r requirements.txt (line 7)) (0.5.1)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from pep517->pip-tools==6.2.0->-r requirements.txt (line 14)) (1.2.2)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter==1.0.0->-r requirements.txt (line 7)) (1.11.2)\n",
            "Building wheels for collected packages: clang, wrapt, ptflops\n",
            "  Building wheel for clang (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30692 sha256=9d85df40f6191aae378d19ecca64d36c53ecf3ceab2b050bda171b630c4da5fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/91/04/971b4c587cf47ae952b108949b46926f426c02832d120a082a\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68719 sha256=619b785522e4e835ee3f822827de8929536b4241b902da173e02e1bc8ab97c67\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "  Building wheel for ptflops (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ptflops: filename=ptflops-0.6.6-py3-none-any.whl size=8903 sha256=e7d3d3c70b6457fd6efa5d513f7d349336c22b2ef2c1cd263f1409ae647d739d\n",
            "  Stored in directory: /root/.cache/pip/wheels/eb/7c/e5/2332373fcac1b39ba9eb95698ac370da3e14eaba5516e22721\n",
            "Successfully built clang wrapt ptflops\n",
            "Installing collected packages: traitlets, typing-extensions, wrapt, torch, tensorboard, scikit-learn, flatbuffers, clang, torchvision, textwrap3, tensorflow, scikit-image, ptflops\n",
            "  Attempting uninstall: traitlets\n",
            "    Found existing installation: traitlets 5.1.1\n",
            "    Uninstalling traitlets-5.1.1:\n",
            "      Successfully uninstalled traitlets-5.1.1\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 3.10.0.2\n",
            "    Uninstalling typing-extensions-3.10.0.2:\n",
            "      Successfully uninstalled typing-extensions-3.10.0.2\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.13.3\n",
            "    Uninstalling wrapt-1.13.3:\n",
            "      Successfully uninstalled wrapt-1.13.3\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.7.0\n",
            "    Uninstalling tensorboard-2.7.0:\n",
            "      Successfully uninstalled tensorboard-2.7.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.1\n",
            "    Uninstalling scikit-learn-1.0.1:\n",
            "      Successfully uninstalled scikit-learn-1.0.1\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.7.0\n",
            "    Uninstalling tensorflow-2.7.0:\n",
            "      Successfully uninstalled tensorflow-2.7.0\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.18.3\n",
            "    Uninstalling scikit-image-0.18.3:\n",
            "      Successfully uninstalled scikit-image-0.18.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.9.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.9.0 which is incompatible.\n",
            "nbclient 0.5.8 requires jupyter-client>=6.1.5, but you have jupyter-client 5.3.5 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.2.post1 which is incompatible.\u001b[0m\n",
            "Successfully installed clang-5.0 flatbuffers-1.12 ptflops-0.6.6 scikit-image-0.16.2 scikit-learn-0.22.2.post1 tensorboard-2.6.0 tensorflow-2.6.0 textwrap3-0.9.2 torch-1.9.0 torchvision-0.10.0 traitlets-5.1.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "traitlets"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-XSXNc61vV3",
        "outputId": "106cbb10-fc3f-425e-d614-ff7d4ab1ea05"
      },
      "source": [
        "# Install Yolov5\n",
        "!cd {root_dir}\n",
        "!git clone https://github.com/joangog/yolov5\n",
        "!pip install -r {os.path.join(root_dir,'yolov5','requirements.txt')}\n",
        "\n",
        "# Replace albumentation augmentations with custom ones\n",
        "!cd utils\n",
        "!rm augmentations.py\n",
        "!cp {os.path.join(root_dir,'scripts','augmentations.py')} {os.path.join(root_dir,'yolov5','utils','augmentations.py')} "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 9899, done.\u001b[K\n",
            "remote: Total 9899 (delta 0), reused 0 (delta 0), pack-reused 9899\u001b[K\n",
            "Receiving objects: 100% (9899/9899), 10.29 MiB | 21.86 MiB/s, done.\n",
            "Resolving deltas: 100% (6861/6861), done.\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov5/requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov5/requirements.txt (line 5)) (1.19.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov5/requirements.txt (line 6)) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov5/requirements.txt (line 7)) (7.1.2)\n",
            "Collecting PyYAML>=5.3.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov5/requirements.txt (line 9)) (2.23.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov5/requirements.txt (line 10)) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov5/requirements.txt (line 11)) (1.9.0)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov5/requirements.txt (line 12)) (0.10.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov5/requirements.txt (line 13)) (4.62.3)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov5/requirements.txt (line 16)) (2.6.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov5/requirements.txt (line 20)) (1.1.5)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov5/requirements.txt (line 21)) (0.11.2)\n",
            "Collecting thop\n",
            "  Downloading thop-0.0.31.post2005241907-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r /content/yolov5/requirements.txt (line 4)) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r /content/yolov5/requirements.txt (line 4)) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r /content/yolov5/requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r /content/yolov5/requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r /content/yolov5/requirements.txt (line 9)) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r /content/yolov5/requirements.txt (line 9)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r /content/yolov5/requirements.txt (line 9)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r /content/yolov5/requirements.txt (line 9)) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->-r /content/yolov5/requirements.txt (line 11)) (3.7.4.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (3.3.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (0.37.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (3.17.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (57.4.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (1.42.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (0.4.6)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (1.35.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->-r /content/yolov5/requirements.txt (line 20)) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (3.1.1)\n",
            "Installing collected packages: thop, PyYAML\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-6.0 thop-0.0.31.post2005241907\n",
            "/bin/bash: line 0: cd: utils: No such file or directory\n",
            "rm: cannot remove 'augmentations.py': No such file or directory\n",
            "cp: cannot stat '/content/scripts/augmentations.py': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYO5_FOUR1D_",
        "outputId": "8a76cb48-f8dc-4835-8ed8-fc9f7a621215"
      },
      "source": [
        "# Install Yolov3\n",
        "!cd {root_dir}\n",
        "!git clone https://github.com/ultralytics/yolov3\n",
        "!pip install -r {os.path.join(root_dir,'yolov3','requirements.txt')}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov3'...\n",
            "remote: Enumerating objects: 9946, done.\u001b[K\n",
            "remote: Counting objects: 100% (88/88), done.\u001b[K\n",
            "remote: Compressing objects: 100% (83/83), done.\u001b[K\n",
            "remote: Total 9946 (delta 15), reused 27 (delta 5), pack-reused 9858\u001b[K\n",
            "Receiving objects: 100% (9946/9946), 9.37 MiB | 21.18 MiB/s, done.\n",
            "Resolving deltas: 100% (6680/6680), done.\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov3/requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov3/requirements.txt (line 5)) (1.19.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov3/requirements.txt (line 6)) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov3/requirements.txt (line 7)) (7.1.2)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov3/requirements.txt (line 8)) (6.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov3/requirements.txt (line 9)) (2.23.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov3/requirements.txt (line 10)) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov3/requirements.txt (line 11)) (1.9.0)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov3/requirements.txt (line 12)) (0.10.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov3/requirements.txt (line 13)) (4.62.3)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov3/requirements.txt (line 16)) (2.6.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov3/requirements.txt (line 20)) (1.1.5)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov3/requirements.txt (line 21)) (0.11.2)\n",
            "Requirement already satisfied: thop in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov3/requirements.txt (line 36)) (0.0.31.post2005241907)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r /content/yolov3/requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r /content/yolov3/requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r /content/yolov3/requirements.txt (line 4)) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r /content/yolov3/requirements.txt (line 4)) (1.3.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r /content/yolov3/requirements.txt (line 9)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r /content/yolov3/requirements.txt (line 9)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r /content/yolov3/requirements.txt (line 9)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r /content/yolov3/requirements.txt (line 9)) (2021.10.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->-r /content/yolov3/requirements.txt (line 11)) (3.7.4.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r /content/yolov3/requirements.txt (line 16)) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r /content/yolov3/requirements.txt (line 16)) (1.8.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r /content/yolov3/requirements.txt (line 16)) (0.37.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r /content/yolov3/requirements.txt (line 16)) (3.17.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r /content/yolov3/requirements.txt (line 16)) (1.35.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r /content/yolov3/requirements.txt (line 16)) (1.42.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r /content/yolov3/requirements.txt (line 16)) (0.12.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r /content/yolov3/requirements.txt (line 16)) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r /content/yolov3/requirements.txt (line 16)) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r /content/yolov3/requirements.txt (line 16)) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r /content/yolov3/requirements.txt (line 16)) (1.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->-r /content/yolov3/requirements.txt (line 20)) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r /content/yolov3/requirements.txt (line 16)) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r /content/yolov3/requirements.txt (line 16)) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r /content/yolov3/requirements.txt (line 16)) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r /content/yolov3/requirements.txt (line 16)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r /content/yolov3/requirements.txt (line 16)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r /content/yolov3/requirements.txt (line 16)) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r /content/yolov3/requirements.txt (line 16)) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r /content/yolov3/requirements.txt (line 16)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r /content/yolov3/requirements.txt (line 16)) (3.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hgn6P8YF3Kv1",
        "outputId": "0116af32-76df-400c-c70b-d762f8941534"
      },
      "source": [
        "# Install unrar command\n",
        "if os.geteuid() != 0:  # If not root, ask for sudo priviledges\n",
        "  from getpass import getpass\n",
        "  password = getpass('Insert sudo password:')\n",
        "  !echo {password} | sudo -S -k apt-get install unrar\n",
        "else:\n",
        "  !apt-get install unrar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unrar is already the newest version (1:5.5.8-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp4s5Q5fdG_x"
      },
      "source": [
        "### Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eZg3dOcWfsV"
      },
      "source": [
        "# Comment google.colab packages if using local runtime\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "\n",
        "import os, sys\n",
        "import math\n",
        "import time\n",
        "import copy\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import xml.etree.ElementTree as ET\n",
        "import PIL\n",
        "import IPython\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torchvision\n",
        "import torchvision.models.detection as M\n",
        "import torchvision.transforms.functional as F\n",
        "import torchvision.utils as U\n",
        "from torchvision.datasets import CocoDetection\n",
        "\n",
        "from pycocotools import coco\n",
        "from pycocotools import mask as cocomask\n",
        "\n",
        "from ptflops import get_model_complexity_info\n",
        "\n",
        "import scripts.utils as SU\n",
        "import scripts.transforms as ST\n",
        "import scripts.engine as SE\n",
        "import scripts.coco_utils as SCU\n",
        "from scripts.coco_eval import CocoEvaluator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBR6LGJI2nbe"
      },
      "source": [
        "### Define auxiliary functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLvVp8ME2xt0"
      },
      "source": [
        "def add_motion_blur(img, kernel_size, kernel_angle):\n",
        "  \n",
        "  kernel = np.zeros((kernel_size, kernel_size))\n",
        "  \n",
        "  if kernel_angle == 'v':  # Vertical Motion Blur\n",
        "    kernel[:, int((kernel_size - 1)/2)] = np.ones(kernel_size)\n",
        "\n",
        "  elif kernel_angle == 'h':  # Horizontal Motion Blur\n",
        "    kernel[int((kernel_size - 1)/2), :] = np.ones(kernel_size)\n",
        "\n",
        "  return cv2.filter2D(img, -1, kernel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hBNZ1E5oHv2"
      },
      "source": [
        "### (Optional) Connect to GDrive for storage access\n",
        "*Note: Not possible with local runtime*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gUb3wQZX9R8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3233cd5a-8850-4a10-fc7d-6a43dfd3ad7a"
      },
      "source": [
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFpoV3E0-smW"
      },
      "source": [
        "### Download Mask dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZmlJ1DpK3ZG"
      },
      "source": [
        "!cd {root_dir}\n",
        "!mkdir -p dataset_{dataset_name}\n",
        "!cd {dataset_dir}\n",
        "!mkdir -p {img_dir} {ann_dir} {label_dir}\n",
        "!cd {img_dir}\n",
        "!mkdir {val_img_dir} {train_img_dir}\n",
        "!cd {label_dir}\n",
        "!mkdir {val_label_dir} {train_label_dir}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLsRgTRRuu3J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "545f3696-e359-4fc4-ea4e-e7b57d0421d6"
      },
      "source": [
        "if dataset_name == 'MASKD':\n",
        "\n",
        "  !cd {root_dir}\n",
        "\n",
        "  # Download validation images\n",
        "  if not os.path.exists('val_images.zip'):\n",
        "    !gdown --id '101F2k6PJ-tD_uwlsCG7zzGF9ILJW01M1'\n",
        "  !unzip -q -n 'val_images.zip' -d {img_dir}\n",
        "\n",
        "  # Download train images\n",
        "  if not os.path.exists('train_images.zip'):\n",
        "    !gdown --id '1vD_Sxg7dHkB_8OJLsHngBWvp5iGJAETQ'\n",
        "  !unzip -q -n 'train_images.zip' -d {img_dir}\n",
        "\n",
        "  # Download validation annotations\n",
        "  if not os.path.exists('val.json'):\n",
        "    !gdown -O {os.path.join(ann_dir,'val.json')} --id '1YLV7-7vmiNdFI8Xpdx_jbhnxfgQRWrgF'\n",
        "\n",
        "  # Download train annotations\n",
        "  if not os.path.exists('train.json'):\n",
        "    !gdown -O {os.path.join(ann_dir,'train.json')}  --id '1AqeDJps-aZ743vFJ6p2_RjtSFjPtIOtD'\n",
        "\n",
        "elif dataset_name == 'PWMFD':\n",
        "\n",
        "  # Download validation images\n",
        "  if not os.path.exists('val_images.rar'):\n",
        "    !gdown -O 'val_images.rar' --id  1ZXuSwoRvTnnca81RUj3kMoLFZJ6auAwT\n",
        "  !unrar e -idq -o- 'val_images.rar' -d {val_img_dir}\n",
        "\n",
        "  # Download train images\n",
        "  if not os.path.exists('train_images.rar'):\n",
        "    !gdown -O 'train_images.rar' --id  16uI5ZEiq2JEYBH4_DhmxVAHSqzY5UQ1b\n",
        "  !unrar e -idq -o- 'train_images.rar' -d {train_img_dir} \n",
        "\n",
        "  # Convert annotation files from PASCAL VOC .xml to COCO .json (only for PWMFD dataset)\n",
        "  \n",
        "  label_ids = {'with_mask': 1, 'without_mask': 2, 'incorrect_mask': 3}  # BG class is 0\n",
        "    \n",
        "  for type_img in ['val', 'train']:\n",
        "\n",
        "    ann_count = 0  # Annotation counter\n",
        "\n",
        "    images = []\n",
        "    categories = []\n",
        "    annotations = []\n",
        "\n",
        "    xml_files = os.listdir(os.path.join(os.path.join(img_dir,f'{type_img}_images')))\n",
        "    xml_files = [file for file in xml_files if '.xml' in file]\n",
        "\n",
        "    # Categories\n",
        "    for label in label_ids:\n",
        "      categories.append(\n",
        "          {\n",
        "            'supercategory': 'none',\n",
        "            'id': label_ids[label],\n",
        "            'name': label\n",
        "          }\n",
        "      )\n",
        "\n",
        "    for xml_file in xml_files:  # For each annotation file\n",
        "\n",
        "      tree = ET.parse(os.path.join(os.path.join(img_dir,f'{type_img}_images'),xml_file))\n",
        "      root = tree.getroot()\n",
        "\n",
        "      # Image\n",
        "      file_name = root[0].text\n",
        "      height = int(root[1][1].text)\n",
        "      width = int(root[1][0].text)\n",
        "      id = int(re.sub(r'^\\D*0*', '', file_name).replace('.jpg',''))\n",
        "      images.append(\n",
        "          {\n",
        "            'file_name': file_name,\n",
        "            'height': height,\n",
        "            'width': width,\n",
        "            'id': id\n",
        "          }\n",
        "      )\n",
        "      \n",
        "      # Annotations\n",
        "      if len(root) > 2:  # If annotations (object attribute) exist, they will be after the 1-index attribute in the XML\n",
        "        for i in range(2,len(root)):\n",
        "          category_id = label_ids[root[i][0].text]\n",
        "          xmin = int(root[i][1][0].text)\n",
        "          ymin = int(root[i][1][1].text)\n",
        "          xmax = int(root[i][1][2].text)\n",
        "          ymax = int(root[i][1][3].text)\n",
        "          annotations.append(\n",
        "              {\n",
        "                'iscrowd': 0,\n",
        "                'image_id': id,\n",
        "                'bbox': [xmin, ymin, xmax-xmin, ymax-ymin],\n",
        "                'area': (xmax-xmin) * (ymax-ymin),\n",
        "                'category_id': category_id,\n",
        "                'ignore': 0,\n",
        "                'id': ann_count,\n",
        "                'segmentation': []\n",
        "              }\n",
        "          )\n",
        "          ann_count += 1\n",
        "\n",
        "    coco_dict = {\n",
        "    'info': {},\n",
        "    'images': images,\n",
        "    'categories': categories,\n",
        "    'annotations': annotations,\n",
        "    'licenses': []\n",
        "    }\n",
        "\n",
        "    with open(os.path.join(ann_dir,f'{type_img}.json'),'w') as outfile:\n",
        "      json.dump(coco_dict, outfile, indent=3)\n",
        "\n",
        "\n",
        "# Copy COCO annotations in images folder\n",
        "!cp {os.path.join(ann_dir,'val.json')} {val_img_dir}\n",
        "!cp {os.path.join(ann_dir,'train.json')} {train_img_dir}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ZXuSwoRvTnnca81RUj3kMoLFZJ6auAwT\n",
            "To: /content/val_images.rar\n",
            "100% 204M/204M [00:01<00:00, 104MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16uI5ZEiq2JEYBH4_DhmxVAHSqzY5UQ1b\n",
            "To: /content/train_images.rar\n",
            "100% 1.13G/1.13G [00:10<00:00, 109MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqD0UEvTBQsD"
      },
      "source": [
        "### (Only for YOLO models) Convert format of annotations from COCO to YOLO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPgZDxhEBPyZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a52091a-b311-4163-8522-3f267becb56a"
      },
      "source": [
        "for type_images in ['val', 'train']:\n",
        "\n",
        "    ann_path = os.path.join(ann_dir, type_images + \".json\")\n",
        "    dataset = coco.COCO(ann_path)\n",
        "    img_ids = dataset.getImgIds()\n",
        "\n",
        "    for img_id in img_ids:\n",
        "\n",
        "      img_anns = dataset.loadAnns(dataset.getAnnIds([img_id]))\n",
        "      img_data = dataset.loadImgs([img_id])[0]\n",
        "      img_file = img_data['file_name']\n",
        "      img_width = img_data['width']\n",
        "      img_height = img_data['height']\n",
        "\n",
        "      label_file = img_file.replace('.jpg','.txt')\n",
        "      \n",
        "      with open(os.path.join(label_dir, f'{type_images}_images', label_file), 'w') as outfile:\n",
        "        for ann in img_anns:\n",
        "          x_center = (ann['bbox'][0] + ann['bbox'][2]/2) / img_width  # convert x_min to x_center and normalize to [0,1]\n",
        "          y_center = (ann['bbox'][1] + ann['bbox'][3]/2) / img_height  # convert y_min to y_center and normalize to [0,1]\n",
        "          width = ann['bbox'][2] / img_width\n",
        "          height = ann['bbox'][3] / img_height \n",
        "          outfile.write(\"{} {} {} {} {}\\n\".format(int(ann['category_id'])-1,x_center,y_center,width,height))   # Category ids must be 0-indexed\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.08s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uara-01_5NIB"
      },
      "source": [
        "### Load Mask dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC4qQcYh5R88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a77c178-496b-4b45-9a4f-417ca1489fdc"
      },
      "source": [
        "val_ann_file = 'val.json'  # annotations\n",
        "val_ann_path = os.path.join(val_img_dir,val_ann_file)  \n",
        "\n",
        "train_ann_file = 'train.json'  # annotations\n",
        "train_ann_path = os.path.join(train_img_dir,train_ann_file)  \n",
        "\n",
        "# Define data transforms\n",
        "transforms = ST.Compose([ST.ToTensor()])\n",
        "\n",
        "# Create datasets\n",
        "val_dataset = CocoDetection(val_img_dir, val_ann_path, transforms = transforms)\n",
        "train_dataset = CocoDetection(train_img_dir, train_ann_path, transforms = transforms)\n",
        "\n",
        "# Create data loaders\n",
        "val_data_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, collate_fn=SU.collate_fn)\n",
        "train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, collate_fn=SU.collate_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.07s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXwGEoyOZfKq"
      },
      "source": [
        "### Load pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "ZVJqPlW8dTvc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 587,
          "referenced_widgets": [
            "ea6fb45340da4e8dacbe2f6e842f7e52",
            "81bbabd7499b42e09a724dae2e41229f",
            "56314b73e1704ad9a58cca47b1d9dddc",
            "7ea64759ee4e4d138fc57bcfed145e49",
            "f73455ba24e54ac088b586bb47ae0d9d",
            "49dcff20a6404e26a3675486d1d8addc",
            "e313a9e33228454296428162115f271e",
            "43d717f078bc4763be9eb390609e8f69",
            "7b674652fe844e5792301b9073b31918",
            "3a0a9ec1e9ff4af083f60deac042a8c3",
            "f90b53b8fbaa4a109f4157448dbff730"
          ]
        },
        "outputId": "9bc4e18b-2a5b-4ba8-cd0d-244e511cabd9"
      },
      "source": [
        "!cd {root_dir}\n",
        "\n",
        "# Delete utils package to reload it (if loaded), because YOLOv3 and YOLOv5 have\n",
        "# the same name for it and it causes error\n",
        "try:\n",
        "  sys.modules.pop('utils')\n",
        "except:\n",
        "  pass\n",
        "\n",
        "# @markdown Model Selection { display-mode: 'form', run: 'auto' }\n",
        "model_name = 'YOLOv5s' # @param ['SSD300 VGG16', 'SSDlite320 MobileNetV3-Large', 'Faster R-CNN ResNet-50 FPN', 'Faster R-CNN MobileNetV3-Large FPN', 'Mask R-CNN ResNet-50 FPN', 'YOLOv5s', 'YOLOv5m', 'YOLOv5l', 'YOLOv3', 'YOLOv3-tiny', 'YOLOv3-spp']\n",
        "\n",
        "# @markdown *Note: If you get the error \"Cache may be out of date, try 'force_reload=True'\" then restart runtime.*\n",
        "\n",
        "if model_name == 'SSD300 VGG16':\n",
        "  model_id = 'ssd300_vgg16'\n",
        "  model = M.ssd300_vgg16(pretrained=True, progress=True)\n",
        "  model_img_size = (3,300,300)\n",
        "elif model_name == 'SSDlite320 MobileNetV3-Large':\n",
        "  model_id = 'ssdlite320_mobilenet_v3_large'\n",
        "  model = M.ssdlite320_mobilenet_v3_large(pretrained=True, progress=True)\n",
        "  model_img_size = (3,320,320)\n",
        "elif model_name == 'Faster R-CNN ResNet-50 FPN':\n",
        "  model_id = 'fasterrcnn_resnet50_fpn'\n",
        "  model = M.fasterrcnn_resnet50_fpn(pretrained=True, progress=True)\n",
        "  model_img_size = (3,800,800) # COCO's 640x640 in upscaled to the model's minimum 800x800\n",
        "elif model_name == 'Faster R-CNN MobileNetV3-Large FPN':\n",
        "  model_id = 'fasterrcnn_mobilenet_v3_large_fpn'\n",
        "  model = M.fasterrcnn_mobilenet_v3_large_fpn(pretrained=True, progress=True)\n",
        "  model_img_size = (3,800,800) \n",
        "elif model_name == 'Mask R-CNN ResNet-50 FPN':\n",
        "  model_id = 'maskrcnn_resnet50_fpn'\n",
        "  model = M.maskrcnn_resnet50_fpn(pretrained=True, progress=True)\n",
        "  model_img_size = (3,800,800)\n",
        "elif model_name == 'YOLOv5s':\n",
        "  model_id = 'yolov5s'\n",
        "  model = torch.hub.load('ultralytics/yolov5', 'yolov5s', force_reload=True)\n",
        "  model_img_size = (3,img_res,img_res)\n",
        "elif model_name == 'YOLOv5m':\n",
        "  model_id = 'yolov5m'\n",
        "  model = torch.hub.load('ultralytics/yolov5', 'yolov5m', force_reload=True)\n",
        "  model_img_size = (3,img_res,img_res)\n",
        "elif model_name == 'YOLOv5l':\n",
        "  model_id = 'yolov5l'\n",
        "  model = torch.hub.load('ultralytics/yolov5', 'yolov5l', force_reload=True)\n",
        "  model_img_size = (3,img_res,img_res)\n",
        "elif model_name == 'YOLOv3':\n",
        "  model_id = 'yolov3'\n",
        "  model = torch.hub.load('ultralytics/yolov3', 'yolov3', force_reload=True)\n",
        "  model_img_size = (3,img_res,img_res)\n",
        "elif model_name == 'YOLOv3-tiny':\n",
        "  model_id = 'yolov3_tiny'\n",
        "  model = torch.hub.load('ultralytics/yolov3', 'yolov3_tiny', force_reload=True)\n",
        "  model_img_size = (3,img_res,img_res)\n",
        "elif model_name == 'YOLOv3-spp':\n",
        "  model_id = 'yolov3_spp'\n",
        "  model = torch.hub.load('ultralytics/yolov3', 'yolov3_spp', force_reload=True)\n",
        "  model_img_size = (3,img_res,img_res)\n",
        "\n",
        "print('-------------------------------------------------------------------------------------------------------\\n')\n",
        "\n",
        "print(f'Loaded model: {model_name}')\n",
        "model_params = round(sum([param.numel() for param in model.parameters()]) / 1000000, 1)\n",
        "print(f'\\t- Parameters: {model_params}M')\n",
        "model_macs, _ = get_model_complexity_info(model, model_img_size, as_strings=False, \n",
        "                                          print_per_layer_stat=False, verbose=False)\n",
        "model_gflops = round(2 * int(model_macs) / 1000000000, 1)\n",
        "print(f'\\t- GFLOPs: {model_gflops}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/ultralytics/yolov5/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m PyYAML>=5.3.1 not found and is required by YOLOv5, attempting auto-update...\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (6.0)\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m torch>=1.7.0 not found and is required by YOLOv5, attempting auto-update...\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (1.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0) (3.7.4.3)\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m torchvision>=0.8.1 not found and is required by YOLOv5, attempting auto-update...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 2021-11-20 torch 1.9.0+cu102 CUDA:0 (Tesla K80, 11441MiB)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.8.1) (1.19.5)\n",
            "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.8.1) (1.9.0)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.8.1) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchvision>=0.8.1) (3.7.4.3)\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m 3 packages updated per /root/.cache/torch/hub/ultralytics_yolov5_master/requirements.txt\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5s.pt to /root/.cache/torch/hub/ultralytics_yolov5_master/yolov5s.pt...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea6fb45340da4e8dacbe2f6e842f7e52",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/14.0M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fusing layers... \n",
            "Model Summary: 213 layers, 7225885 parameters, 0 gradients\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------------------------------------------\n",
            "\n",
            "Loaded model: YOLOv5s\n",
            "\t- Parameters: 7.2M\n",
            "\t- GFLOPs: 4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foMMd-OQ7GMv"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0hskTBqjSOj"
      },
      "source": [
        "### (Optional) Open Tensorboard Monitor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyI5lrXoMw9K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "ff4a312d-24c6-40af-faca-b894fe1cb742"
      },
      "source": [
        "# Load Tensorboard\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --bind_all --logdir {save_ckpt_dir}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvGK5hUw-q_k"
      },
      "source": [
        "### Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94J_kCy--zPp",
        "outputId": "9743c095-8010-474b-97af-6721ec3d5eee"
      },
      "source": [
        "# Set model checkpoint folder\n",
        "start_time = int(time.time())\n",
        "save_ckpt_folder = f'{dataset_name}_{model_id}_{start_time}_run'\n",
        "\n",
        "# Prepare model for new dataset (for Fast R-CNN or Mask R-CNN)\n",
        "if 'R-CNN' in model_name: \n",
        "  num_classes = len(val_dataset.coco.getCatIds())+1  # includes background (0) class\n",
        "  # Get the number of input features for the bbox predictor\n",
        "  in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "  # Replace the pre-trained head with a new one\n",
        "  model.roi_heads.box_predictor = M.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
        "  if 'Mask R-CNN' in model_name:\n",
        "    # Get the number of input features for the segmentation max predictor\n",
        "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "    hidden_layer = 256\n",
        "    # Replace the mask predictor with a new one\n",
        "    model.roi_heads.mask_predictor = M.mask_rcnn.MaskRCNNPredictor(in_features_mask, hidden_layer,num_classes)\n",
        "\n",
        "# Model Training \n",
        "\n",
        "if 'YOLO' in model_name: # For YOLO models\n",
        "\n",
        "  yolo_version = int(model_id[5])\n",
        "\n",
        "  # Generate hyperparameter file\n",
        "  %cp {root_dir}/yolov{yolo_version}/data/{'hyps/' if yolo_version == 5 else ''}hyp.scratch.yaml {root_dir}/hyp.yaml\n",
        "  with open('hyp.yaml','a') as outfile:\n",
        "    outfile.write(\n",
        "\n",
        "f\"\"\"lr0: {lr}\n",
        "momentum: {momentum}\n",
        "weight_decay: {weight_decay}\"\"\"\n",
        "\n",
        ")\n",
        "\n",
        "  train_script_path = os.path.join(root_dir,f'yolov{yolo_version}','train.py')\n",
        "  data_path = os.path.join(root_dir,'config',f'{dataset_name}_yolov{yolo_version}.yaml')\n",
        "\n",
        "  if load_ckpt:  # If load a pre-existing checkpoint, resume from it\n",
        "    temp_save_ckpt_folder = re.search(r'/' + dataset_name + '[^/]*/', load_ckpt_path).group(0).replace('/','')  # Get the save folder name from the loaded folder name\n",
        "    temp_load_ckpt_path = load_ckpt_path\n",
        "  else:  # If not load a pre-existing checkpoint, load pre-trained COCO weights or randomly initialize weights\n",
        "    if pretrained:\n",
        "      temp_save_ckpt_folder = save_ckpt_folder\n",
        "      temp_load_ckpt_path = f'{model_id.replace(\"_\",\"-\")}.pt'\n",
        "    else:\n",
        "      temp_save_ckpt_folder = save_ckpt_folder\n",
        "      temp_load_ckpt_path = '\"\"'\n",
        "  if load_cfg:  # If load custom model config\n",
        "    temp_cfg_path = load_cfg_path\n",
        "  else:\n",
        "    temp_cfg_path = model_id.replace(\"_\",\"-\") + '.yaml'\n",
        "\n",
        "  !python {train_script_path} --img {img_res} --epochs {num_epochs} --batch {batch_size} --project {save_ckpt_dir} --name {temp_save_ckpt_folder} --hyp \"hyp.yaml\" --data {data_path} \\\n",
        "  {'--resume ' + temp_load_ckpt_path if load_ckpt else '--weights ' + temp_load_ckpt_path} \\\n",
        "  {'--adam' if optimizer_type=='adam' else ''} \\\n",
        "  {'--cfg '  +  temp_cfg_path}\n",
        "\n",
        "else: # For all the other models\n",
        "\n",
        "  # Make checkpoint folder\n",
        "  !mkdir {os.path.join(ckpt_dir,ckpt_folder)}\n",
        "\n",
        "  # Load pre-existing checkpoint weights if required\n",
        "  last_epoch = 0\n",
        "  if load_ckpt:\n",
        "    model.load_state_dict(torch.load(load_ckpt_path))\n",
        "    last_epoch = int(re.search(r'epoch[0-9]+', load_ckpt_path).group(0)[5:])\n",
        "    print(f'Loaded checkpoint: {load_ckpt_path}')\n",
        "\n",
        "  # Get appropriate device for model\n",
        "  device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "  model.to(device)\n",
        "  print(f'Pre-trained Model: {model_name}')\n",
        "\n",
        "  # Construct an optimizer\n",
        "  params = [p for p in model.parameters() if p.requires_grad]\n",
        "  if optimizer_type == 'adam':\n",
        "    optimizer = torch.optim.Adam(params, lr=lr, weight_decay=weight_decay)\n",
        "  elif optimizer_type == 'sgd':\n",
        "    optimizer = torch.optim.SGD(params, lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
        "\n",
        "  # Construct learning rate scheduler\n",
        "  lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "  # Save training configs to .txt\n",
        "  config_path = os.path.join(save_ckpt_dir,save_ckpt_folder,'cfg.txt')\n",
        "  with open(config_path,'w') as outfile:\n",
        "    outfile.write( \n",
        "                         \n",
        "f\"\"\"dataset: {dataset_name}\n",
        "model: {model_id}\n",
        "timestamp: {start_time}\n",
        "last_checkpoint: {load_ckpt_path if load_ckpt else None}\n",
        "num_epochs: {num_epochs}\n",
        "batch_size: {batch_size}\n",
        "optimizer: {optimizer_type}\n",
        "learning_rate: {lr}\n",
        "step_size: {step_size}\n",
        "gamma: {gamma}\n",
        "momentum: {momentum}\n",
        "weight_decay: {weight_decay}\"\"\"\n",
        "\n",
        ")\n",
        "\n",
        "  # Train model\n",
        "  for epoch in range(num_epochs):\n",
        "\n",
        "      curr_epoch = last_epoch + epoch + 1\n",
        "\n",
        "      # Train for one epoch, printing every 10 iterations\n",
        "      metric_logger = SE.train_one_epoch(model, optimizer, train_data_loader, device, epoch, print_freq=1)\n",
        "      \n",
        "      # Update the learning rate\n",
        "      lr_scheduler.step()\n",
        "      \n",
        "      # Evaluate on the test dataset\n",
        "      evaluator, _, _, _ = SE.evaluate(model, val_data_loader, device)\n",
        "\n",
        "      # Save model checkpoint\n",
        "      ckpt_file = f'epoch{curr_epoch}'\n",
        "      ckpt_path = os.path.join(ckpt_dir,ckpt_folder,ckpt_file)\n",
        "      torch.save(model.state_dict(), ckpt_path)\n",
        "\n",
        "      # Delete previous model checkpoint\n",
        "      previous_ckpt_file = f'epoch{curr_epoch-1}'\n",
        "      if os.path.exists(previous_ckpt_file):\n",
        "        os.remove(previous_ckpt_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5/yolov5s.pt, cfg=/content/config/yolov5s-tr-exp.yaml, data=/content/config/PWMFD_yolov5.yaml, hyp=hyp.yaml, epochs=50, batch_size=32, imgsz=320, rect=False, resume=/content/drive/MyDrive/object-detection-checkpoints/PWMFD_yolov5s_1637236944_run/weights/last.pt, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=/content/drive/MyDrive/object-detection-checkpoints, name=PWMFD_yolov5s_1637236944_run, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=0, save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/joangog/yolov5 ✅\n",
            "Resuming training from /content/drive/MyDrive/object-detection-checkpoints/PWMFD_yolov5s_1637236944_run/weights/last.pt\n",
            "YOLOv5 🚀 v6.0-87-ge00b065 torch 1.9.0+cu102 CUDA:0 (Tesla K80, 11441MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/object-detection-checkpoints', view at http://localhost:6006/\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182976  models.common.C3TR                      [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90944  models.common.C3TR                      [256, 128, 1]                 \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296576  models.common.C3TR                      [256, 256, 1]                 \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182976  models.common.C3TR                      [512, 512, 1]                 \n",
            " 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model Summary: 274 layers, 7028424 parameters, 7028424 gradients, 15.0 GFLOPs\n",
            "\n",
            "Transferred 345/345 items from /content/drive/MyDrive/object-detection-checkpoints/PWMFD_yolov5s_1637236944_run/weights/last.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 49 weight, 80 weight (no decay), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mmodule 'albumentations' has no attribute 'BboxParams'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'dataset_PWMFD/labels/train_images' images and labels...3441 found, 0 missing, 1 empty, 0 corrupted:  47% 3441/7385 [00:02<00:02, 1693.10it/s]/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 4. \n",
            "  warnings.warn(str(msg))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'dataset_PWMFD/labels/train_images' images and labels...7385 found, 0 missing, 1 empty, 0 corrupted: 100% 7385/7385 [00:05<00:00, 1321.08it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/000140.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/000250.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/000256.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/000307.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/000627.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/000855.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/000992.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/001043.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/001074.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/001280.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/001392.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/001481.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/002031.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/002158.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/004669.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/004694.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/004737.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/004771.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/004773.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/004782.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/004796.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/004813.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/004876.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/004946.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/004993.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/005011.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/005056.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/005098.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/005129.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/005200.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/005264.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/005265.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/005266.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/005269.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/007218.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/007228.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/007920.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/007968.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/008021.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/008762.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/008792.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/008796.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: dataset_PWMFD/images/train_images/008869.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: dataset_PWMFD/labels/train_images.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'dataset_PWMFD/labels/val_images' images and labels...1119 found, 0 missing, 0 empty, 0 corrupted:  61% 1119/1820 [00:02<00:01, 594.77it/s]/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'dataset_PWMFD/labels/val_images' images and labels...1820 found, 0 missing, 0 empty, 0 corrupted: 100% 1820/1820 [00:03<00:00, 512.82it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING: dataset_PWMFD/images/val_images/000567.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING: dataset_PWMFD/images/val_images/000867.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING: dataset_PWMFD/images/val_images/001131.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING: dataset_PWMFD/images/val_images/001309.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING: dataset_PWMFD/images/val_images/001367.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING: dataset_PWMFD/images/val_images/001492.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING: dataset_PWMFD/images/val_images/001571.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING: dataset_PWMFD/images/val_images/001588.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING: dataset_PWMFD/images/val_images/001905.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING: dataset_PWMFD/images/val_images/001991.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING: dataset_PWMFD/images/val_images/004863.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING: dataset_PWMFD/images/val_images/005062.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING: dataset_PWMFD/images/val_images/005134.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: dataset_PWMFD/labels/val_images.cache\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Image sizes 320 train, 320 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/object-detection-checkpoints/PWMFD_yolov5s_1637236944_run\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     43/49     7.95G   0.02813   0.01284  0.002225        91       320: 100% 231/231 [08:51<00:00,  2.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 29/29 [00:38<00:00,  1.31s/it]\n",
            "                 all       1820       1830      0.946      0.978      0.974      0.712\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     44/49     9.19G   0.02762   0.01272  0.002217       104       320: 100% 231/231 [08:50<00:00,  2.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 29/29 [00:37<00:00,  1.29s/it]\n",
            "                 all       1820       1830      0.942      0.961      0.973      0.723\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     45/49     9.19G   0.02759   0.01259  0.002033       108       320: 100% 231/231 [08:43<00:00,  2.26s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 29/29 [00:37<00:00,  1.31s/it]\n",
            "                 all       1820       1830      0.933      0.971      0.975       0.72\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     46/49     9.19G   0.02762   0.01267  0.001962        93       320: 100% 231/231 [08:46<00:00,  2.28s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 29/29 [00:37<00:00,  1.30s/it]\n",
            "                 all       1820       1830      0.944      0.972      0.975      0.717\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     47/49     9.19G   0.02766   0.01262  0.001828        78       320: 100% 231/231 [08:47<00:00,  2.28s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 29/29 [00:38<00:00,  1.32s/it]\n",
            "                 all       1820       1830      0.914      0.964      0.967      0.719\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     48/49     9.19G   0.02709   0.01248  0.001953        69       320: 100% 231/231 [08:43<00:00,  2.26s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 29/29 [00:36<00:00,  1.26s/it]\n",
            "                 all       1820       1830      0.945      0.965      0.972      0.721\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     49/49     9.19G   0.02731   0.01257  0.001843        81       320: 100% 231/231 [08:43<00:00,  2.26s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 29/29 [00:38<00:00,  1.32s/it]\n",
            "                 all       1820       1830      0.931      0.975      0.974      0.729\n",
            "\n",
            "7 epochs completed in 1.099 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/object-detection-checkpoints/PWMFD_yolov5s_1637236944_run/weights/last.pt, 14.3MB\n",
            "Optimizer stripped from /content/drive/MyDrive/object-detection-checkpoints/PWMFD_yolov5s_1637236944_run/weights/best.pt, 14.3MB\n",
            "\n",
            "Validating /content/drive/MyDrive/object-detection-checkpoints/PWMFD_yolov5s_1637236944_run/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model Summary: 225 layers, 7020328 parameters, 0 gradients, 15.0 GFLOPs\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 29/29 [00:34<00:00,  1.17s/it]\n",
            "                 all       1820       1830      0.931      0.975      0.974      0.728\n",
            "           with_mask       1820        993      0.972      0.972      0.985      0.735\n",
            "        without_mask       1820        791      0.921      0.975      0.967      0.686\n",
            "      incorrect_mask       1820         46        0.9      0.978      0.969      0.763\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/object-detection-checkpoints/PWMFD_yolov5s_1637236944_run\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}