{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "coco2017_inference.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "l9IQxr2jWaui",
        "Lp4s5Q5fdG_x",
        "uEmfFmE6cl7U",
        "zPcMtX-sxDW7",
        "40IKqODFFBGY",
        "-PhLjHCmTpDS"
      ],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "872fc32c73b14b46bfa9d20f5a4aca5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b00489a0a5f49fb931df9bcc68ece7d",
              "IPY_MODEL_0dd6352ec9a14305b9070c594c4285bb",
              "IPY_MODEL_f382ca66684f43fb9d42158b0262bc9e"
            ],
            "layout": "IPY_MODEL_0af99347aa454e43a12116e36cb429a8"
          }
        },
        "6b00489a0a5f49fb931df9bcc68ece7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca572db54df04aba91ab07d26394dfc9",
            "placeholder": "​",
            "style": "IPY_MODEL_491c918ce84346afa13a42fe94bc7dc3",
            "value": "100%"
          }
        },
        "0dd6352ec9a14305b9070c594c4285bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_986b3b6063a842b09dca12ae466088b3",
            "max": 167502836,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a1e47470baa41c88a4b73088e8181fa",
            "value": 167502836
          }
        },
        "f382ca66684f43fb9d42158b0262bc9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff86694cc1c940b78a1c8bfd1daee98e",
            "placeholder": "​",
            "style": "IPY_MODEL_5a842a4c1fda4773b39c71034ef18107",
            "value": " 160M/160M [01:14&lt;00:00, 2.26MB/s]"
          }
        },
        "0af99347aa454e43a12116e36cb429a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca572db54df04aba91ab07d26394dfc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "491c918ce84346afa13a42fe94bc7dc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "986b3b6063a842b09dca12ae466088b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a1e47470baa41c88a4b73088e8181fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff86694cc1c940b78a1c8bfd1daee98e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a842a4c1fda4773b39c71034ef18107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joangog/object-detection/blob/main/coco2017_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIjcsMslUx9m"
      },
      "source": [
        "## Model evaluation (inference) on COCO 2017 dataset\n",
        "\n",
        "The following models will be evaluated:\n",
        "\n",
        "| Model | Backbone | Image Size | Parameters | GFLOPs\n",
        "| --- | --- | --- | --- | --- |\n",
        "| SSDlite320 | MobileNetV3-Large | 320x320 | 3.4M | 1.2 |\n",
        "| SSD300 | VGG16 | 300x300 | 35.6M | 69.8 |\n",
        "| Faster R-CNN |  MobileNetV3-Large FPN | 800x800 | 19.4M | 9.1 |\n",
        "| Faster R-CNN |  ResNet-50 FPN | 800x800 | 41.8M | 269.1 |\n",
        "| Mask R-CNN |  ResNet-50 FPN | 800x800 | 44.4M | 269.1 |\n",
        "| YOLOv5s |  Custom | 640x640 | 7.3M | 17 |\n",
        "| YOLOv5m |  Custom | 640x640 | 21.4M | 51.3 |\n",
        "| YOLOv5l |  Custom |640x640 | 47M | 115.5 |\n",
        "| YOLOv3-tiny |  Darknet53 | 640x640 | 8.8M | 13.3 |\n",
        "| YOLOv3 |  Darknet53 | 640x640 | 61.9M | 156.3 |\n",
        "| YOLOv3-spp |  Darknet53 | 640x640 | 63M | 157.1 |\n",
        "\n",
        "<br>\n",
        "\n",
        "**Note: GPU Runtime needed (hosted or local)**\n",
        "\n",
        "*Example experiment: Tesla K80, 460.32.03, 11441 MiB, batch_size=8 (or 1), workers=2*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4X0kW-fHdG9R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0aa5c63-646d-4e86-a26a-ef1531bf9184"
      },
      "source": [
        "# Show system specs\n",
        "!nvidia-smi --query-gpu=gpu_name,driver_version,memory.total --format=csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name, driver_version, memory.total [MiB]\r\n",
            "GeForce GTX 960, 460.91.03, 4036 MiB\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVojvH9i8ua0"
      },
      "source": [
        "### Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZHe4nxx8raL"
      },
      "source": [
        "# Parameters\n",
        "\n",
        "num_workers = 2  #  Data loader workers\n",
        "batch_size = 1  # Data loader batch size\n",
        "\n",
        "th = 0.5  # Threshold for confidence score of predicted bboxes to show\n",
        "\n",
        "# Directories\n",
        "\n",
        "import os\n",
        "root_dir = os.getcwd()  # Root dir of project\n",
        "dataset_dir = os.path.join(root_dir,'dataset_COCO')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9IQxr2jWaui"
      },
      "source": [
        "### Get requirements\n",
        "*Note: Restart runtime after installation*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-XSXNc61vV3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd13495d-70e4-4b40-a175-4e419d4f1d31"
      },
      "source": [
        "# Install Yolov5\n",
        "!cd {root_dir}\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "!pip install -r {os.path.join(root_dir,'yolov5','requirements.txt')}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'yolov5' already exists and is not an empty directory.\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in ./anaconda3/lib/python3.8/site-packages (from -r /home/ioanna/yolov5/requirements.txt (line 4)) (3.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in ./anaconda3/lib/python3.8/site-packages (from -r /home/ioanna/yolov5/requirements.txt (line 5)) (1.19.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in ./anaconda3/lib/python3.8/site-packages (from -r /home/ioanna/yolov5/requirements.txt (line 6)) (4.5.3.56)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in ./anaconda3/lib/python3.8/site-packages (from -r /home/ioanna/yolov5/requirements.txt (line 7)) (8.0.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in ./anaconda3/lib/python3.8/site-packages (from -r /home/ioanna/yolov5/requirements.txt (line 8)) (5.3.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in ./anaconda3/lib/python3.8/site-packages (from -r /home/ioanna/yolov5/requirements.txt (line 9)) (1.5.2)\n",
            "Requirement already satisfied: torch>=1.7.0 in ./anaconda3/lib/python3.8/site-packages (from -r /home/ioanna/yolov5/requirements.txt (line 10)) (1.9.1)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in ./anaconda3/lib/python3.8/site-packages (from -r /home/ioanna/yolov5/requirements.txt (line 11)) (0.10.1)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in ./anaconda3/lib/python3.8/site-packages (from -r /home/ioanna/yolov5/requirements.txt (line 12)) (4.50.2)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in ./anaconda3/lib/python3.8/site-packages (from -r /home/ioanna/yolov5/requirements.txt (line 15)) (2.6.0)\n",
            "Requirement already satisfied: pandas in ./anaconda3/lib/python3.8/site-packages (from -r /home/ioanna/yolov5/requirements.txt (line 19)) (1.1.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in ./anaconda3/lib/python3.8/site-packages (from -r /home/ioanna/yolov5/requirements.txt (line 20)) (0.11.0)\n",
            "Requirement already satisfied: thop in ./anaconda3/lib/python3.8/site-packages (from -r /home/ioanna/yolov5/requirements.txt (line 35)) (0.0.31.post2005241907)\n",
            "Requirement already satisfied: certifi>=2020.06.20 in ./anaconda3/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r /home/ioanna/yolov5/requirements.txt (line 4)) (2020.6.20)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in ./anaconda3/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r /home/ioanna/yolov5/requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in ./anaconda3/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r /home/ioanna/yolov5/requirements.txt (line 4)) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in ./anaconda3/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r /home/ioanna/yolov5/requirements.txt (line 4)) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in ./anaconda3/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r /home/ioanna/yolov5/requirements.txt (line 4)) (0.10.0)\n",
            "Requirement already satisfied: typing-extensions in ./anaconda3/lib/python3.8/site-packages (from torch>=1.7.0->-r /home/ioanna/yolov5/requirements.txt (line 10)) (3.7.4.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in ./anaconda3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 15)) (50.3.1.post20201107)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in ./anaconda3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 15)) (1.33.2)\n",
            "Requirement already satisfied: wheel>=0.26 in ./anaconda3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 15)) (0.35.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in ./anaconda3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 15)) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in ./anaconda3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 15)) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in ./anaconda3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 15)) (0.12.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./anaconda3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 15)) (0.4.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in ./anaconda3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 15)) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in ./anaconda3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 15)) (1.28.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in ./anaconda3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 15)) (2.24.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./anaconda3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 15)) (1.6.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in ./anaconda3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 15)) (3.14.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in ./anaconda3/lib/python3.8/site-packages (from pandas->-r /home/ioanna/yolov5/requirements.txt (line 19)) (2020.1)\n",
            "Requirement already satisfied: six>=1.5 in ./anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.1->matplotlib>=3.2.2->-r /home/ioanna/yolov5/requirements.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 15)) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in ./anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 15)) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 15)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in ./anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 15)) (4.7.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in ./anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 15)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in ./anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 15)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 15)) (1.25.11)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in ./anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 15)) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 15)) (0.4.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYO5_FOUR1D_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bb3512c-b777-4bcd-9119-f8a08bd828ec"
      },
      "source": [
        "# Install Yolov3\n",
        "!cd {root_dir}\n",
        "!git clone https://github.com/ultralytics/yolov3\n",
        "!pip install -r {os.path.join(root_dir,'yolov3','requirements.txt')}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'yolov3' already exists and is not an empty directory.\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in ./anaconda3/lib/python3.8/site-packages (from -r /home/ioanna/yolov3/requirements.txt (line 4)) (3.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in ./anaconda3/lib/python3.8/site-packages (from -r /home/ioanna/yolov3/requirements.txt (line 5)) (1.19.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in ./anaconda3/lib/python3.8/site-packages (from -r /home/ioanna/yolov3/requirements.txt (line 6)) (4.5.3.56)\n",
            "Requirement already satisfied: Pillow in ./anaconda3/lib/python3.8/site-packages (from -r /home/ioanna/yolov3/requirements.txt (line 7)) (8.0.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in ./anaconda3/lib/python3.8/site-packages (from -r /home/ioanna/yolov3/requirements.txt (line 8)) (5.3.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in ./anaconda3/lib/python3.8/site-packages (from -r /home/ioanna/yolov3/requirements.txt (line 9)) (1.5.2)\n",
            "Requirement already satisfied: torch>=1.7.0 in ./anaconda3/lib/python3.8/site-packages (from -r /home/ioanna/yolov3/requirements.txt (line 10)) (1.9.1)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in ./anaconda3/lib/python3.8/site-packages (from -r /home/ioanna/yolov3/requirements.txt (line 11)) (0.10.1)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in ./anaconda3/lib/python3.8/site-packages (from -r /home/ioanna/yolov3/requirements.txt (line 12)) (4.50.2)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in ./anaconda3/lib/python3.8/site-packages (from -r /home/ioanna/yolov3/requirements.txt (line 15)) (2.6.0)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in ./anaconda3/lib/python3.8/site-packages (from -r /home/ioanna/yolov3/requirements.txt (line 19)) (0.11.0)\n",
            "Requirement already satisfied: pandas in ./anaconda3/lib/python3.8/site-packages (from -r /home/ioanna/yolov3/requirements.txt (line 20)) (1.1.3)\n",
            "Requirement already satisfied: pycocotools>=2.0 in ./anaconda3/lib/python3.8/site-packages (from -r /home/ioanna/yolov3/requirements.txt (line 29)) (2.0.2)\n",
            "Requirement already satisfied: thop in ./anaconda3/lib/python3.8/site-packages (from -r /home/ioanna/yolov3/requirements.txt (line 30)) (0.0.31.post2005241907)\n",
            "Requirement already satisfied: cycler>=0.10 in ./anaconda3/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r /home/ioanna/yolov3/requirements.txt (line 4)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in ./anaconda3/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r /home/ioanna/yolov3/requirements.txt (line 4)) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in ./anaconda3/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r /home/ioanna/yolov3/requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2020.06.20 in ./anaconda3/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r /home/ioanna/yolov3/requirements.txt (line 4)) (2020.6.20)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in ./anaconda3/lib/python3.8/site-packages (from matplotlib>=3.2.2->-r /home/ioanna/yolov3/requirements.txt (line 4)) (2.8.1)\n",
            "Requirement already satisfied: typing-extensions in ./anaconda3/lib/python3.8/site-packages (from torch>=1.7.0->-r /home/ioanna/yolov3/requirements.txt (line 10)) (3.7.4.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./anaconda3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (1.6.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in ./anaconda3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (3.14.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in ./anaconda3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (1.33.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in ./anaconda3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in ./anaconda3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (50.3.1.post20201107)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./anaconda3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (0.4.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in ./anaconda3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (2.24.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in ./anaconda3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in ./anaconda3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in ./anaconda3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (0.35.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in ./anaconda3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (1.28.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in ./anaconda3/lib/python3.8/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (0.12.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in ./anaconda3/lib/python3.8/site-packages (from pandas->-r /home/ioanna/yolov3/requirements.txt (line 20)) (2020.1)\n",
            "Requirement already satisfied: cython>=0.27.3 in ./anaconda3/lib/python3.8/site-packages (from pycocotools>=2.0->-r /home/ioanna/yolov3/requirements.txt (line 29)) (0.29.21)\n",
            "Requirement already satisfied: six in ./anaconda3/lib/python3.8/site-packages (from cycler>=0.10->matplotlib>=3.2.2->-r /home/ioanna/yolov3/requirements.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in ./anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in ./anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (1.25.11)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in ./anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in ./anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (4.2.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in ./anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (0.4.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gWOqjlQQdaP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cd3c9d6-00e2-4983-e66c-dff65c0efafd"
      },
      "source": [
        "# Clone asset files\n",
        "!cd {root_dir}\n",
        "!git clone https://github.com/joangog/object-detection-assets\n",
        "!mv -n {os.path.join(root_dir,'object-detection-assets','scripts')} ./\n",
        "!mv -n {os.path.join(root_dir,'object-detection-assets','requirements.txt')} ./\n",
        "!rm -rf {os.path.join(root_dir,'object-detection-assets')}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'object-detection-assets'...\n",
            "remote: Enumerating objects: 108, done.\u001b[K\n",
            "remote: Counting objects: 100% (108/108), done.\u001b[K\n",
            "remote: Compressing objects: 100% (77/77), done.\u001b[K\n",
            "remote: Total 108 (delta 37), reused 88 (delta 20), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (108/108), 23.73 KiB | 837.00 KiB/s, done.\n",
            "Resolving deltas: 100% (37/37), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVa0AxzKlSyv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16533181-a4ef-4ec5-f231-cf35b55b5156"
      },
      "source": [
        "# Install packages\n",
        "!cd {root_dir}\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in ./anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (4.0.1)\r\n",
            "Requirement already satisfied: numpy in ./anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (1.19.2)\r\n",
            "Requirement already satisfied: pandas in ./anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (1.1.3)\r\n",
            "Requirement already satisfied: matplotlib in ./anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (3.3.2)\n",
            "Requirement already satisfied: torch in ./anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (1.9.1)\n",
            "Requirement already satisfied: torchvision in ./anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (0.10.1)\n",
            "Requirement already satisfied: ptflops in ./anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (0.6.6)\n",
            "Requirement already satisfied: textwrap3 in ./anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (0.9.2)\n",
            "Requirement already satisfied: requests[socks]>=2.12.0 in ./anaconda3/lib/python3.8/site-packages (from gdown->-r requirements.txt (line 1)) (2.24.0)\n",
            "Requirement already satisfied: filelock in ./anaconda3/lib/python3.8/site-packages (from gdown->-r requirements.txt (line 1)) (3.0.12)\n",
            "Requirement already satisfied: six in ./anaconda3/lib/python3.8/site-packages (from gdown->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: tqdm in ./anaconda3/lib/python3.8/site-packages (from gdown->-r requirements.txt (line 1)) (4.50.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in ./anaconda3/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 3)) (2020.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in ./anaconda3/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 3)) (2.8.1)\n",
            "Requirement already satisfied: certifi>=2020.06.20 in ./anaconda3/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 4)) (2020.6.20)\n",
            "Requirement already satisfied: pillow>=6.2.0 in ./anaconda3/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 4)) (8.0.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in ./anaconda3/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 4)) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in ./anaconda3/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in ./anaconda3/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 4)) (0.10.0)\n",
            "Requirement already satisfied: typing-extensions in ./anaconda3/lib/python3.8/site-packages (from torch->-r requirements.txt (line 5)) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in ./anaconda3/lib/python3.8/site-packages (from requests[socks]>=2.12.0->gdown->-r requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in ./anaconda3/lib/python3.8/site-packages (from requests[socks]>=2.12.0->gdown->-r requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./anaconda3/lib/python3.8/site-packages (from requests[socks]>=2.12.0->gdown->-r requirements.txt (line 1)) (1.25.11)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in ./anaconda3/lib/python3.8/site-packages (from requests[socks]>=2.12.0->gdown->-r requirements.txt (line 1)) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp4s5Q5fdG_x"
      },
      "source": [
        "### Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eZg3dOcWfsV"
      },
      "source": [
        "# Comment google.colab packages if using local runtime\n",
        "# from google.colab import files\n",
        "# from google.colab import drive\n",
        "\n",
        "import gdown\n",
        "\n",
        "import os, sys\n",
        "import math\n",
        "import time\n",
        "import copy\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import PIL\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.models.detection as M\n",
        "import torchvision.transforms.functional as F\n",
        "import torchvision.utils as U\n",
        "from torchvision.datasets import CocoDetection\n",
        "\n",
        "from ptflops import get_model_complexity_info\n",
        "\n",
        "import scripts.utils as SU\n",
        "import scripts.transforms as ST\n",
        "import scripts.engine as SE\n",
        "import scripts.coco_utils as SCU\n",
        "from scripts.coco_eval import CocoEvaluator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoYuEECPX2mQ"
      },
      "source": [
        "### (Optional) Connect to GDrive for storage access\n",
        "*Note: Not possible with local runtime*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gUb3wQZX9R8"
      },
      "source": [
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFpoV3E0-smW"
      },
      "source": [
        "### Download COCO 2017 validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGZH-ZSzu6nK"
      },
      "source": [
        "!cd {root_dir}\n",
        "!mkdir -p dataset_COCO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6rHTrcZ1Wle"
      },
      "source": [
        "# Download images\n",
        "!wget -nc http://images.cocodataset.org/zips/val2017.zip\n",
        "!unzip -q -n val2017.zip -d {dataset_dir}\n",
        "\n",
        "!cd {dataset_dir}\n",
        "\n",
        "# Download annotations\n",
        "!wget -nc http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
        "!unzip -q -n annotations_trainval2017.zip -d {dataset_dir}\n",
        "!cp {os.path.join(dataset_dir,'annotations','instances_val2017.json')} {os.path.join(dataset_dir,'val2017')}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uara-01_5NIB"
      },
      "source": [
        "### Load COCO 2017 validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC4qQcYh5R88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feeaad32-20f9-4f9f-ef0b-2ad5cbdf10bd"
      },
      "source": [
        "img_dir = os.path.join(dataset_dir,'val2017')\n",
        "ann_file = 'instances_val2017.json'  # annotations\n",
        "ann_path = os.path.join(img_dir,ann_file)\n",
        "\n",
        "# Define data transforms\n",
        "transforms = ST.Compose([ST.ToTensor()])\n",
        "\n",
        "# Create dataset\n",
        "dataset = CocoDetection(img_dir, ann_path, transforms = transforms)\n",
        "\n",
        "# Create data loader\n",
        "data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, collate_fn=SU.collate_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.59s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEmfFmE6cl7U"
      },
      "source": [
        "### (Optional) Get dataset resolution information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxkvhAL0Stnv"
      },
      "source": [
        "img_ids = dataset.coco.getImgIds()\n",
        "img_x_arr = []\n",
        "img_y_arr = []\n",
        "\n",
        "for img_id in img_ids:\n",
        "  img = PIL.Image.open(os.path.join(img_dir,dataset.coco.loadImgs([img_id])[0]['file_name']))\n",
        "  img_tensor = F.convert_image_dtype(F.to_tensor(img),torch.uint8)\n",
        "  img_shape = img_tensor.shape\n",
        "  img_x_arr.append(img_shape[1])\n",
        "  img_y_arr.append(img_shape[2])\n",
        "\n",
        "img_x_mean = np.mean(img_x_arr)\n",
        "img_y_mean = np.mean(img_y_arr)\n",
        "\n",
        "img_x_max = np.max(img_x_arr)\n",
        "img_y_max = np.max(img_y_arr)\n",
        "\n",
        "print(f'Mean resolution: {img_x_mean,img_y_mean}')\n",
        "print(f'Maximum resolution: {img_x_max,img_y_max}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXwGEoyOZfKq"
      },
      "source": [
        "### Load pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVJqPlW8dTvc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162,
          "referenced_widgets": [
            "872fc32c73b14b46bfa9d20f5a4aca5e",
            "6b00489a0a5f49fb931df9bcc68ece7d",
            "0dd6352ec9a14305b9070c594c4285bb",
            "f382ca66684f43fb9d42158b0262bc9e",
            "0af99347aa454e43a12116e36cb429a8",
            "ca572db54df04aba91ab07d26394dfc9",
            "491c918ce84346afa13a42fe94bc7dc3",
            "986b3b6063a842b09dca12ae466088b3",
            "5a1e47470baa41c88a4b73088e8181fa",
            "ff86694cc1c940b78a1c8bfd1daee98e",
            "5a842a4c1fda4773b39c71034ef18107"
          ]
        },
        "cellView": "form",
        "outputId": "c8838c7d-adfd-4131-f31e-f8076a20e0b5"
      },
      "source": [
        "!cd {root_dir}\n",
        "\n",
        "# Delete utils package to reload it (if loaded), because YOLOv3 and YOLOv5 have\n",
        "# the same name for it and it causes error\n",
        "try:\n",
        "  sys.modules.pop('utils')\n",
        "except:\n",
        "  pass\n",
        "\n",
        "# @markdown Model Selection { display-mode: 'form', run: 'auto' }\n",
        "model_name = 'Faster R-CNN ResNet-50 FPN' # @param ['SSD300 VGG16', 'SSDlite320 MobileNetV3-Large', 'Faster R-CNN ResNet-50 FPN', 'Faster R-CNN MobileNetV3-Large FPN', 'Mask R-CNN ResNet-50 FPN', 'YOLOv5s', 'YOLOv5m', 'YOLOv5l', 'YOLOv3', 'YOLOv3-tiny', 'YOLOv3-spp']\n",
        "\n",
        "# @markdown *Note: If you get the error \"Cache may be out of date, try 'force_reload=True'\" then restart runtime.*\n",
        "\n",
        "if model_name == 'SSD300 VGG16':\n",
        "  model_id = 'ssd300_vgg16'\n",
        "  model = M.ssd300_vgg16(pretrained=True, progress=True)\n",
        "  model_img_size = (3,300,300)\n",
        "elif model_name == 'SSDlite320 MobileNetV3-Large':\n",
        "  model_id = 'ssdlite320_mobilenet_v3_large'\n",
        "  model = M.ssdlite320_mobilenet_v3_large(pretrained=True, progress=True)\n",
        "  model_img_size = (3,320,320)\n",
        "elif model_name == 'Faster R-CNN ResNet-50 FPN':\n",
        "  model_id = 'fasterrcnn_resnet50_fpn'\n",
        "  model = M.fasterrcnn_resnet50_fpn(pretrained=True, progress=True)\n",
        "  model_img_size = (3,800,800) # COCO's 640x640 in upscaled to the model's minimum 800x800\n",
        "elif model_name == 'Faster R-CNN MobileNetV3-Large FPN':\n",
        "  model_id = 'fasterrcnn_mobilenet_v3_large_fpn'\n",
        "  model = M.fasterrcnn_mobilenet_v3_large_fpn(pretrained=True, progress=True)\n",
        "  model_img_size = (3,800,800) \n",
        "elif model_name == 'Mask R-CNN ResNet-50 FPN':\n",
        "  model_id = 'maskrcnn_resnet50_fpn'\n",
        "  model = M.maskrcnn_resnet50_fpn(pretrained=True, progress=True)\n",
        "  model_img_size = (3,800,800)\n",
        "elif model_name == 'YOLOv5s':\n",
        "  model_id = 'yolov5s'\n",
        "  model = torch.hub.load('ultralytics/yolov5', 'yolov5s', force_reload=True)\n",
        "  model_img_size = (3,640,640)\n",
        "elif model_name == 'YOLOv5m':\n",
        "  model_id = 'yolov5m'\n",
        "  model = torch.hub.load('ultralytics/yolov5', 'yolov5m', force_reload=True)\n",
        "  model_img_size = (3,640,640)\n",
        "elif model_name == 'YOLOv5l':\n",
        "  model_id = 'yolov5l'\n",
        "  model = torch.hub.load('ultralytics/yolov5', 'yolov5l', force_reload=True)\n",
        "  model_img_size = (3,640,640)\n",
        "elif model_name == 'YOLOv3':\n",
        "  model_id = 'yolov3'\n",
        "  model = torch.hub.load('ultralytics/yolov3', 'yolov3', force_reload=True)\n",
        "  model_img_size = (3,640,640)\n",
        "elif model_name == 'YOLOv3-tiny':\n",
        "  model_id = 'yolov3_tiny'\n",
        "  model = torch.hub.load('ultralytics/yolov3', 'yolov3_tiny', force_reload=True)\n",
        "  model_img_size = (3,640,640)\n",
        "elif model_name == 'YOLOv3-spp':\n",
        "  model_id = 'yolov3_spp'\n",
        "  model = torch.hub.load('ultralytics/yolov3', 'yolov3_spp', force_reload=True)\n",
        "  model_img_size = (3,640,640)\n",
        "\n",
        "print('-------------------------------------------------------------------------------------------------------\\n')\n",
        "\n",
        "print(f'Loaded model: {model_name}')\n",
        "model_params = round(sum([param.numel() for param in model.parameters()]) / 1000000, 1)\n",
        "print(f'\\t- Parameters: {model_params}M')\n",
        "model_macs, _ = get_model_complexity_info(model, model_img_size, as_strings=False, \n",
        "                                          print_per_layer_stat=False, verbose=False)\n",
        "model_gflops = round(2 * int(model_macs) / 1000000000, 1)\n",
        "print(f'\\t- GFLOPs: {model_gflops}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /home/ioanna/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=167502836.0), HTML(value='')))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "872fc32c73b14b46bfa9d20f5a4aca5e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------------------------------------------------------------------------------------------------------\n",
            "\n",
            "Loaded model: Faster R-CNN ResNet-50 FPN\n",
            "\t- Parameters: 41.8M\n",
            "\t- GFLOPs: 257.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPcMtX-sxDW7"
      },
      "source": [
        "### (Optional) Test model with image sample\n",
        "*Note 1: If you get the error \"module 'PIL.TiffTags' has no attribute 'IFD'\" then restart runtime.*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRnDnuP-xC99"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# Parameters\n",
        "img_id = 139\n",
        "\n",
        "# Get appropriate device for model\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Get image sample\n",
        "img = PIL.Image.open(os.path.join(img_dir,dataset.coco.loadImgs([img_id])[0]['file_name']))\n",
        "img_tensor = F.convert_image_dtype(F.to_tensor(img),torch.uint8)\n",
        "img_torchvision = torch.div(img_tensor,255).float().to(device)  # Format image for torchvision models\n",
        "img_anns = dataset.coco.loadAnns(dataset.coco.getAnnIds([img_id]))\n",
        "\n",
        "# Get label names\n",
        "label_ids = dataset.coco.getCatIds()\n",
        "label_info = dataset.coco.loadCats(label_ids)\n",
        "label_names = [label['name'] for label in label_info]\n",
        "labels = dict(zip(label_ids,label_names))  # Label dictionary with id-name as key-value\n",
        "labels_inv = dict(zip(label_names,label_ids))  # Inverse label dictionary with name-id as key-value\n",
        "\n",
        "# Format image\n",
        "img_tensor = F.convert_image_dtype(F.to_tensor(img),torch.uint8)\n",
        "img_torchvision = torch.div(img_tensor,255).float().to(device)  # Format image for torchvision models\n",
        "img_anns = dataset.coco.loadAnns(dataset.coco.getAnnIds([img_id]))\n",
        "\n",
        "# Get ground truth bboxes\n",
        "true_bboxes = SE.convert_to_xyxy(copy.deepcopy(F.Tensor([obj['bbox'] for obj in img_anns]).to(device)))  # Create deep copy to avoid updating original dataset\n",
        "true_labels = [labels[obj['category_id']] for obj in img_anns]\n",
        "true_img = U.draw_bounding_boxes(img_tensor, true_bboxes, true_labels)\n",
        "plt.figure(figsize = (25,7))\n",
        "plt.title('Ground Truth Detection')\n",
        "plot = plt.imshow(F.to_pil_image(true_img))\n",
        "\n",
        "# Generate model predictions\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  if 'YOLO' in model_name:\n",
        "    pred = model([img])\n",
        "  else:    \n",
        "    pred = model([img_torchvision])\n",
        "\n",
        "# Get predicted bboxes\n",
        "# For YOLO models\n",
        "if 'YOLO' in model_name:  \n",
        "  pred_bboxes = []\n",
        "  pred_label_ids = []\n",
        "  pred_labels = []\n",
        "  for bbox in pred.xyxy[0]:  # For every bbox\n",
        "    conf = bbox[4]\n",
        "    if conf > th:  # Show only bboxes with high confidence score\n",
        "      pred_bboxes.append(bbox[:4])\n",
        "      label_id = labels_inv[label_names[int(bbox[5])]]  # Convert YOLO label id to COCO label id\n",
        "      pred_label_ids.append(label_id)  \n",
        "      pred_labels.append(labels[label_id] + f'[{int(conf*100)}%]')\n",
        "  if len(pred_bboxes) != 0:\n",
        "    pred_bboxes = torch.stack(pred_bboxes)\n",
        "\n",
        "# For torchvision models\n",
        "else:\n",
        "  for i, bbox in enumerate(pred[0]['boxes']):  # For every bbox\n",
        "    conf = pred[0]['scores'][i]\n",
        "    if conf > th:  # Show only bboxes with high confidence score\n",
        "      pred_bboxes.append(bbox)\n",
        "      label_id = pred[0]['labels'][i]\n",
        "      pred_label_ids.append(label_id)\n",
        "      pred_labels.append(labels[label_id] + f'[{int(conf*100)}%]')\n",
        "  if len(pred_bboxes) != 0:\n",
        "    pred_bboxes = torch.stack(pred_bboxes)\n",
        "\n",
        "if len(pred_bboxes) != 0:\n",
        "  pred_img = U.draw_bounding_boxes(img_tensor, pred_bboxes, pred_labels)\n",
        "else:  # If no bboxes are found just return the image\n",
        "  pred_img = img_tensor\n",
        "plt.figure(figsize = (25,7))\n",
        "plt.title(f'Predicted Detection (thresh={th})')\n",
        "plot = plt.imshow(F.to_pil_image(pred_img))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d4E0DKJ4bOg"
      },
      "source": [
        "### Evaluate model\n",
        "*Note 1: If you get the error \"module 'PIL.TiffTags' has no attribute 'IFD'\" then restart runtime.*\n",
        "\n",
        "*Note 2: To get accurate maximum GPU memory usage logging, restart runtime when choosing a different model.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BViZf4Ud4Vrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63c1d309-bf3d-460c-8033-c9447d50934e"
      },
      "source": [
        "# Get appropriate device for model\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "print(f'Model: {model_name}')\n",
        "\n",
        "# Evaluate model\n",
        "evaluator, fps, max_mem, outputs = SE.evaluate(model, data_loader, device)\n",
        "\n",
        "print(f'fps: {fps}\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Faster R-CNN ResNet-50 FPN\n",
            "Test:  [   0/5000]  eta: 0:38:20  model_time: 0.3395 (0.3395)  evaluator_time: 0.0183 (0.0183)  time: 0.4602  data: 0.1012  max mem: 570\n",
            "Test:  [ 100/5000]  eta: 0:24:29  model_time: 0.2817 (0.2882)  evaluator_time: 0.0065 (0.0087)  time: 0.2892  data: 0.0012  max mem: 607\n",
            "Test:  [ 200/5000]  eta: 0:23:53  model_time: 0.2796 (0.2875)  evaluator_time: 0.0047 (0.0086)  time: 0.2949  data: 0.0011  max mem: 607\n",
            "Test:  [ 300/5000]  eta: 0:23:12  model_time: 0.2824 (0.2862)  evaluator_time: 0.0062 (0.0086)  time: 0.2996  data: 0.0012  max mem: 607\n",
            "Test:  [ 400/5000]  eta: 0:22:28  model_time: 0.2804 (0.2847)  evaluator_time: 0.0052 (0.0085)  time: 0.2641  data: 0.0011  max mem: 607\n",
            "Test:  [ 500/5000]  eta: 0:21:53  model_time: 0.2818 (0.2837)  evaluator_time: 0.0069 (0.0083)  time: 0.2881  data: 0.0012  max mem: 607\n",
            "Test:  [ 600/5000]  eta: 0:21:26  model_time: 0.2828 (0.2845)  evaluator_time: 0.0055 (0.0085)  time: 0.2940  data: 0.0012  max mem: 607\n",
            "Test:  [ 700/5000]  eta: 0:21:02  model_time: 0.2992 (0.2853)  evaluator_time: 0.0054 (0.0086)  time: 0.2985  data: 0.0012  max mem: 607\n",
            "Test:  [ 800/5000]  eta: 0:20:36  model_time: 0.2861 (0.2858)  evaluator_time: 0.0073 (0.0086)  time: 0.2983  data: 0.0013  max mem: 607\n",
            "Test:  [ 900/5000]  eta: 0:20:06  model_time: 0.2810 (0.2861)  evaluator_time: 0.0053 (0.0086)  time: 0.2986  data: 0.0012  max mem: 607\n",
            "Test:  [1000/5000]  eta: 0:19:37  model_time: 0.2862 (0.2862)  evaluator_time: 0.0046 (0.0085)  time: 0.3015  data: 0.0012  max mem: 607\n",
            "Test:  [1100/5000]  eta: 0:19:08  model_time: 0.2793 (0.2864)  evaluator_time: 0.0066 (0.0085)  time: 0.2962  data: 0.0012  max mem: 607\n",
            "Test:  [1200/5000]  eta: 0:18:41  model_time: 0.2997 (0.2868)  evaluator_time: 0.0064 (0.0085)  time: 0.3047  data: 0.0012  max mem: 607\n",
            "Test:  [1300/5000]  eta: 0:18:12  model_time: 0.2818 (0.2868)  evaluator_time: 0.0046 (0.0086)  time: 0.2963  data: 0.0012  max mem: 607\n",
            "Test:  [1400/5000]  eta: 0:17:43  model_time: 0.2822 (0.2864)  evaluator_time: 0.0050 (0.0090)  time: 0.2951  data: 0.0012  max mem: 607\n",
            "Test:  [1500/5000]  eta: 0:17:13  model_time: 0.2782 (0.2861)  evaluator_time: 0.0054 (0.0089)  time: 0.2942  data: 0.0012  max mem: 607\n",
            "Test:  [1600/5000]  eta: 0:16:42  model_time: 0.2977 (0.2861)  evaluator_time: 0.0063 (0.0089)  time: 0.3084  data: 0.0013  max mem: 607\n",
            "Test:  [1700/5000]  eta: 0:16:13  model_time: 0.3020 (0.2861)  evaluator_time: 0.0045 (0.0089)  time: 0.3011  data: 0.0012  max mem: 607\n",
            "Test:  [1800/5000]  eta: 0:15:42  model_time: 0.2928 (0.2860)  evaluator_time: 0.0041 (0.0088)  time: 0.2917  data: 0.0012  max mem: 607\n",
            "Test:  [1900/5000]  eta: 0:15:13  model_time: 0.2738 (0.2858)  evaluator_time: 0.0040 (0.0088)  time: 0.2860  data: 0.0012  max mem: 607\n",
            "Test:  [2000/5000]  eta: 0:14:42  model_time: 0.2798 (0.2857)  evaluator_time: 0.0060 (0.0088)  time: 0.2816  data: 0.0012  max mem: 607\n",
            "Test:  [2100/5000]  eta: 0:14:13  model_time: 0.2873 (0.2857)  evaluator_time: 0.0056 (0.0088)  time: 0.2823  data: 0.0012  max mem: 607\n",
            "Test:  [2200/5000]  eta: 0:13:43  model_time: 0.2786 (0.2855)  evaluator_time: 0.0046 (0.0087)  time: 0.2860  data: 0.0011  max mem: 607\n",
            "Test:  [2300/5000]  eta: 0:13:13  model_time: 0.2832 (0.2857)  evaluator_time: 0.0053 (0.0087)  time: 0.2901  data: 0.0012  max mem: 607\n",
            "Test:  [2400/5000]  eta: 0:12:43  model_time: 0.2805 (0.2859)  evaluator_time: 0.0059 (0.0086)  time: 0.2825  data: 0.0012  max mem: 607\n",
            "Test:  [2500/5000]  eta: 0:12:15  model_time: 0.2839 (0.2861)  evaluator_time: 0.0055 (0.0086)  time: 0.3003  data: 0.0013  max mem: 607\n",
            "Test:  [2600/5000]  eta: 0:11:45  model_time: 0.2762 (0.2860)  evaluator_time: 0.0056 (0.0086)  time: 0.2894  data: 0.0026  max mem: 607\n",
            "Test:  [2700/5000]  eta: 0:11:15  model_time: 0.2921 (0.2858)  evaluator_time: 0.0054 (0.0086)  time: 0.2798  data: 0.0036  max mem: 607\n",
            "Test:  [2800/5000]  eta: 0:10:45  model_time: 0.2790 (0.2856)  evaluator_time: 0.0054 (0.0086)  time: 0.2914  data: 0.0012  max mem: 607\n",
            "Test:  [2900/5000]  eta: 0:10:17  model_time: 0.2906 (0.2858)  evaluator_time: 0.0057 (0.0086)  time: 0.2978  data: 0.0011  max mem: 607\n",
            "Test:  [3000/5000]  eta: 0:09:47  model_time: 0.2792 (0.2857)  evaluator_time: 0.0049 (0.0086)  time: 0.2936  data: 0.0012  max mem: 607\n",
            "Test:  [3100/5000]  eta: 0:09:18  model_time: 0.2825 (0.2859)  evaluator_time: 0.0045 (0.0086)  time: 0.2957  data: 0.0012  max mem: 607\n",
            "Test:  [3200/5000]  eta: 0:08:49  model_time: 0.2688 (0.2859)  evaluator_time: 0.0054 (0.0085)  time: 0.2854  data: 0.0011  max mem: 607\n",
            "Test:  [3300/5000]  eta: 0:08:19  model_time: 0.2965 (0.2859)  evaluator_time: 0.0065 (0.0086)  time: 0.3036  data: 0.0012  max mem: 607\n",
            "Test:  [3400/5000]  eta: 0:07:50  model_time: 0.2792 (0.2859)  evaluator_time: 0.0056 (0.0086)  time: 0.2877  data: 0.0012  max mem: 607\n",
            "Test:  [3500/5000]  eta: 0:07:20  model_time: 0.2805 (0.2859)  evaluator_time: 0.0046 (0.0086)  time: 0.2795  data: 0.0012  max mem: 607\n",
            "Test:  [3600/5000]  eta: 0:06:51  model_time: 0.2800 (0.2858)  evaluator_time: 0.0052 (0.0086)  time: 0.2975  data: 0.0013  max mem: 607\n",
            "Test:  [3700/5000]  eta: 0:06:22  model_time: 0.2983 (0.2859)  evaluator_time: 0.0056 (0.0086)  time: 0.2996  data: 0.0012  max mem: 607\n",
            "Test:  [3800/5000]  eta: 0:05:52  model_time: 0.2964 (0.2860)  evaluator_time: 0.0057 (0.0086)  time: 0.3052  data: 0.0013  max mem: 607\n",
            "Test:  [3900/5000]  eta: 0:05:23  model_time: 0.2776 (0.2860)  evaluator_time: 0.0047 (0.0085)  time: 0.2882  data: 0.0012  max mem: 607\n",
            "Test:  [4000/5000]  eta: 0:04:53  model_time: 0.2799 (0.2859)  evaluator_time: 0.0051 (0.0085)  time: 0.2764  data: 0.0012  max mem: 607\n",
            "Test:  [4100/5000]  eta: 0:04:24  model_time: 0.2987 (0.2859)  evaluator_time: 0.0056 (0.0085)  time: 0.3029  data: 0.0012  max mem: 607\n",
            "Test:  [4200/5000]  eta: 0:03:55  model_time: 0.2903 (0.2860)  evaluator_time: 0.0052 (0.0085)  time: 0.3041  data: 0.0012  max mem: 607\n",
            "Test:  [4300/5000]  eta: 0:03:25  model_time: 0.2670 (0.2859)  evaluator_time: 0.0055 (0.0085)  time: 0.2803  data: 0.0012  max mem: 607\n",
            "Test:  [4400/5000]  eta: 0:02:56  model_time: 0.2780 (0.2859)  evaluator_time: 0.0054 (0.0085)  time: 0.2997  data: 0.0012  max mem: 607\n",
            "Test:  [4500/5000]  eta: 0:02:26  model_time: 0.2820 (0.2859)  evaluator_time: 0.0058 (0.0085)  time: 0.3026  data: 0.0013  max mem: 607\n",
            "Test:  [4600/5000]  eta: 0:01:57  model_time: 0.3006 (0.2859)  evaluator_time: 0.0050 (0.0085)  time: 0.3028  data: 0.0011  max mem: 607\n",
            "Test:  [4700/5000]  eta: 0:01:28  model_time: 0.2816 (0.2859)  evaluator_time: 0.0049 (0.0084)  time: 0.3015  data: 0.0012  max mem: 607\n",
            "Test:  [4800/5000]  eta: 0:00:58  model_time: 0.2824 (0.2859)  evaluator_time: 0.0056 (0.0084)  time: 0.3013  data: 0.0012  max mem: 607\n",
            "Test:  [4900/5000]  eta: 0:00:29  model_time: 0.2798 (0.2859)  evaluator_time: 0.0056 (0.0084)  time: 0.2918  data: 0.0012  max mem: 607\n",
            "Test:  [4999/5000]  eta: 0:00:00  model_time: 0.3009 (0.2859)  evaluator_time: 0.0046 (0.0084)  time: 0.2997  data: 0.0011  max mem: 607\n",
            "Test: Total time: 0:24:28 (0.2937 s / it)\n",
            "Averaged stats: model_time: 0.3009 (0.2859)  evaluator_time: 0.0046 (0.0084)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=6.00s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.370\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.586\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.396\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.212\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.403\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.482\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.307\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.485\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.509\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.317\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.544\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.649\n",
            "fps: 3.4974850300097344\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40IKqODFFBGY"
      },
      "source": [
        "### (Optional) Save output results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PY3apojFTt2f"
      },
      "source": [
        "# Format to COCO output json \n",
        "# out_results = []\n",
        "# for i, img_id in enumerate(img_ids):  # For every image\n",
        "#   img_predictions = outputs[i]\n",
        "#   pred_boxes = img_predictions['boxes'].tolist()\n",
        "#   pred_labels = img_predictions['labels'].tolist()\n",
        "#   pred_scores = img_predictions['scores'].tolist()\n",
        "#   for j in range(0,len(pred_box)):  # For every predicted object\n",
        "#     pred_box = pred_boxes[j]\n",
        "#     out_results.append({\n",
        "#         'image_id': img_id,\n",
        "#         'category_id': pred_labels[j],\n",
        "#         'bbox': [round(val,1) for val in pred_box],  # Round for lower file size\n",
        "#         'score': pred_scores[j]\n",
        "#         })\n",
        "\n",
        "# # Save file\n",
        "# results_dir = '/content'\n",
        "# out_results_file = f'coco17_{model_id}_outputs.json'\n",
        "# out_results_path = os.path.join(results_dir, out_results_file)\n",
        "# with open(out_results_file, 'w') as outfile: \n",
        "#     json.dump(out_results, outfile, indent = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PhLjHCmTpDS"
      },
      "source": [
        "### Save metric results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8L2RtxdkDVz"
      },
      "source": [
        "cols = ['model', 'model_params', 'model_gflops', 'fps', 'max_mem', 'iou_type', 'metric', 'iou', 'area', 'max_dets', 'score']\n",
        "model = []\n",
        "model_params_arr = []\n",
        "model_gflops_arr = []\n",
        "fps_arr = []\n",
        "max_mem_arr = []\n",
        "iou_type = []\n",
        "metric = []\n",
        "iou = []\n",
        "area = []\n",
        "max_dets = []\n",
        "score = []\n",
        "\n",
        "# Set column values\n",
        "for curr_iou_type, coco_eval in evaluator.coco_eval.items():\n",
        "  model += [model_name for i in range(0,12)]\n",
        "  model_params_arr += [model_params for i in range(0,12)]\n",
        "  model_gflops_arr += [model_gflops for i in range(0,12)]\n",
        "  fps_arr += [fps for i in range(0,12)]\n",
        "  max_mem_arr += [max_mem for i in range(0,12)]\n",
        "  iou_type += [curr_iou_type for i in range(0,12)]\n",
        "  metric += ['avg_precision' for i in range(0,6)] + ['avg_recall' for i in range(0,6)]\n",
        "  iou += ['0.50:0.95', '0.50', '0.75'] + ['0.50:0.95' for i in range(0,9)]\n",
        "  area += ['all' for i in range(0,3)] + ['small', 'medium', 'large'] + ['all' for i in range(0,3)] + ['small', 'medium', 'large'] \n",
        "  max_dets += [100 for i in range(0,6)] + [1, 10] + [100 for i in range(0,4)]\n",
        "  score += list(coco_eval.stats)\n",
        "\n",
        "metric_results = pd.DataFrame(np.column_stack([model, model_params_arr, model_gflops_arr, fps_arr, max_mem_arr, iou_type, metric, iou, area, max_dets, score]))\n",
        "metric_results.columns = cols"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhLzrHGOP7AP"
      },
      "source": [
        "# Save to file\n",
        "\n",
        "results_dir = root_dir\n",
        "\n",
        "gpu = torch.cuda.get_device_name(0).lower()\n",
        "for pattern in [' ', 'tesla', 'geforce']:  # Keep only short gpu name\n",
        "  gpu = gpu.replace(pattern,'')\n",
        "\n",
        "metric_results_file = f'coco17_{gpu}_{model_id}_metrics.csv'\n",
        "metric_results_path = os.path.join(results_dir, metric_results_file)\n",
        "\n",
        "if os.path.exists(metric_results_path):\n",
        "      os.remove(metric_results_path)\n",
        "with open(metric_results_path, 'w') as outfile: \n",
        "    metric_results.to_csv(outfile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4gtutCucXKQ"
      },
      "source": [
        "### (Optional) Save results to GDrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paaLy2Kzi_xg"
      },
      "source": [
        "# Save to GDrive\n",
        "gdrive_results_dir = '/content/drive/MyDrive/object-detection-results/coco2017'\n",
        "gdrive_metric_results_path = os.path.join(gdrive_results_dir, metric_results_file)\n",
        "if os.path.exists(gdrive_metric_results_path):\n",
        "      os.remove(gdrive_metric_results_path)\n",
        "with open(gdrive_metric_results_path, 'w') as outfile: \n",
        "    metric_results.to_csv(outfile)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}