{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mask_inference.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNd3JINqA95cCZdcmUPeKPK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joangog/object-detection/blob/main/mask_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOnnttZXkP41"
      },
      "source": [
        "## Model evaluation (inference) on COCO 2017 dataset\n",
        "\n",
        "The following models will be evaluated:\n",
        "\n",
        "| Model | Backbone | Image Size | Parameters | GFLOPs\n",
        "| --- | --- | --- | --- | --- |\n",
        "| YOLOv5s |  Custom | 640x640 | 7.3M | 17 |\n",
        "| YOLOv5m |  Custom | 640x640 | 21.4M | 51.3 |\n",
        "| YOLOv5l |  Custom |640x640 | 47M | 115.5 |\n",
        "| YOLOv3-tiny |  Darknet53 | 640x640 | 8.8M | 13.3 |\n",
        "\n",
        "<br>\n",
        "\n",
        "**Note: GPU Runtime needed**\n",
        "\n",
        "*Example experiment: Tesla K80, 460.32.03, 11441 MiB, batch_size=8, workers=2*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X0kW-fHdG9R",
        "outputId": "4d99d740-76de-40f2-fe07-b5258991b34f"
      },
      "source": [
        "# Show system specs\n",
        "!nvidia-smi --query-gpu=gpu_name,driver_version,memory.total --format=csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name, driver_version, memory.total [MiB]\n",
            "Tesla K80, 460.32.03, 11441 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9IQxr2jWaui"
      },
      "source": [
        "### Get requirements\n",
        "*Note: Restart runtime after installation*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-XSXNc61vV3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11301204-4d01-4dfc-e8c8-808168dbff5b"
      },
      "source": [
        "%%shell\n",
        "\n",
        "# Install Yolov5\n",
        "cd /content\n",
        "git clone https://github.com/ultralytics/yolov5\n",
        "cd yolov5\n",
        "pip install --quiet -r requirements.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 9300, done.\u001b[K\n",
            "remote: Total 9300 (delta 0), reused 0 (delta 0), pack-reused 9300\u001b[K\n",
            "Receiving objects: 100% (9300/9300), 9.73 MiB | 17.48 MiB/s, done.\n",
            "Resolving deltas: 100% (6464/6464), done.\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 7.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 636 kB 70.4 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYO5_FOUR1D_",
        "outputId": "a4d48cf0-c4d7-416e-80b4-e843da2fa1a6"
      },
      "source": [
        "%%shell\n",
        "\n",
        "# Install Yolov3\n",
        "cd /content\n",
        "git clone https://github.com/ultralytics/yolov3\n",
        "cd yolov3\n",
        "pip install --quiet -r requirements.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov3'...\n",
            "remote: Enumerating objects: 9862, done.\u001b[K\n",
            "remote: Total 9862 (delta 0), reused 0 (delta 0), pack-reused 9862\u001b[K\n",
            "Receiving objects: 100% (9862/9862), 9.19 MiB | 14.68 MiB/s, done.\n",
            "Resolving deltas: 100% (6666/6666), done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVa0AxzKlSyv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ede98e47-0b32-4fcd-cc19-9bca3a7c7b1e"
      },
      "source": [
        "%%shell\n",
        "\n",
        "# Install flops-counter\n",
        "pip install ptflops"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ptflops\n",
            "  Downloading ptflops-0.6.6.tar.gz (11 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from ptflops) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->ptflops) (3.7.4.3)\n",
            "Building wheels for collected packages: ptflops\n",
            "  Building wheel for ptflops (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ptflops: filename=ptflops-0.6.6-py3-none-any.whl size=8903 sha256=f2c757b2b1657a12f9c339c79ba32e9b2a8a392f74dece54294f7401ad5a7c77\n",
            "  Stored in directory: /root/.cache/pip/wheels/eb/7c/e5/2332373fcac1b39ba9eb95698ac370da3e14eaba5516e22721\n",
            "Successfully built ptflops\n",
            "Installing collected packages: ptflops\n",
            "Successfully installed ptflops-0.6.6\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gWOqjlQQdaP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ddcb494-6d67-4756-daab-630609b3063b"
      },
      "source": [
        "%%shell\n",
        "\n",
        "# Clone asset files\n",
        "cd /content\n",
        "git clone https://github.com/joangog/object-detection-assets\n",
        "cd object-detection-assets\n",
        "mv scripts ../\n",
        "rm -rf /content/object-detection-assets/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'object-detection-assets'...\n",
            "remote: Enumerating objects: 59, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 59 (delta 14), reused 51 (delta 9), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (59/59), done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp4s5Q5fdG_x"
      },
      "source": [
        "### Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eZg3dOcWfsV"
      },
      "source": [
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "\n",
        "import os, sys\n",
        "import math\n",
        "import time\n",
        "import copy\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import PIL\n",
        "import IPython\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torchvision\n",
        "import torchvision.models.detection as M\n",
        "import torchvision.transforms.functional as F\n",
        "import torchvision.utils as U\n",
        "from torchvision.datasets import CocoDetection\n",
        "\n",
        "from pycocotools import coco\n",
        "from pycocotools import mask as cocomask\n",
        "\n",
        "from ptflops import get_model_complexity_info\n",
        "\n",
        "import scripts.utils as SU\n",
        "import scripts.transforms as ST\n",
        "import scripts.engine as SE\n",
        "import scripts.coco_utils as SCU\n",
        "from scripts.coco_eval import CocoEvaluator"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFpoV3E0-smW"
      },
      "source": [
        "### Download Mask dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLsRgTRRuu3J",
        "outputId": "09d7c0b3-b0b0-483f-b0a7-abfce7426879"
      },
      "source": [
        "%%shell\n",
        "\n",
        "cd /content\n",
        "mkdir -p dataset\n",
        "cd dataset\n",
        "mkdir -p images annotations labels\n",
        "cd labels\n",
        "mkdir val_images\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6rHTrcZ1Wle",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3d30227-dad5-431d-b3ec-4f60791ba5e8"
      },
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/dataset/images\n",
        "\n",
        "# Download validation images\n",
        "gdown --id '101F2k6PJ-tD_uwlsCG7zzGF9ILJW01M1'\n",
        "unzip -q -n 'val_images.zip'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=101F2k6PJ-tD_uwlsCG7zzGF9ILJW01M1\n",
            "To: /content/dataset/images/val_images.zip\n",
            "14.9MB [00:01, 9.23MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIvrZuC_1YK0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbc945ce-e61e-4172-8f53-314640a35eb6"
      },
      "source": [
        "%%shell\n",
        "\n",
        "cd /content/dataset/annotations\n",
        "\n",
        "# Download validation annotations\n",
        "gdown --id '1YLV7-7vmiNdFI8Xpdx_jbhnxfgQRWrgF'\n",
        "cp '/content/dataset/annotations/val.json' '/content/dataset/images/val_images'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1YLV7-7vmiNdFI8Xpdx_jbhnxfgQRWrgF\n",
            "To: /content/dataset/annotations/val.json\n",
            "100% 105k/105k [00:00<00:00, 923kB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uara-01_5NIB"
      },
      "source": [
        "### Load Mask dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC4qQcYh5R88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d51a5a39-906d-47f0-d306-4b085c4e73c6"
      },
      "source": [
        "val_img_dir = '/content/dataset/images/val_images'\n",
        "val_ann_file = 'val.json'  # annotations\n",
        "val_ann_path = os.path.join(val_img_dir,val_ann_file)  \n",
        "\n",
        "# Define data transforms\n",
        "transforms = ST.Compose([ST.ToTensor()])\n",
        "\n",
        "# Create dataset\n",
        "val_dataset = CocoDetection(val_img_dir, val_ann_path, transforms = transforms)\n",
        "\n",
        "# Create data loader\n",
        "batch_size = 1\n",
        "num_workers = 2\n",
        "val_data_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, collate_fn=SU.collate_fn)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXwGEoyOZfKq"
      },
      "source": [
        "### Load model checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5Wr5Qf3pmoI",
        "outputId": "007a46c1-c6c5-4680-8f0d-e1b55a32e313"
      },
      "source": [
        "# Mount GDrive to load model checkpoint\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVJqPlW8dTvc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "06091daa-8bde-48b6-a5b1-4f096750b35d"
      },
      "source": [
        "load_ckpt_path = '/content/drive/MyDrive/object-detection-checkpoints/pretrained/MASKD_yolov5s_sgd_ep100_lr01_run/weights/last.pt'\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-b57758afd378>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mload_ckpt_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/object-detection-checkpoints/pretrained/MASKD_yolov5s_sgd_ep100_lr01_run/weights/last.pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_ckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1407\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1408\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for AutoShape:\n\tMissing key(s) in state_dict: \"model.model.0.conv.conv.weight\", \"model.model.0.conv.bn.weight\", \"model.model.0.conv.bn.bias\", \"model.model.0.conv.bn.running_mean\", \"model.model.0.conv.bn.running_var\", \"model.model.1.conv.weight\", \"model.model.1.bn.weight\", \"model.model.1.bn.bias\", \"model.model.1.bn.running_mean\", \"model.model.1.bn.running_var\", \"model.model.2.cv1.conv.weight\", \"model.model.2.cv1.bn.weight\", \"model.model.2.cv1.bn.bias\", \"model.model.2.cv1.bn.running_mean\", \"model.model.2.cv1.bn.running_var\", \"model.model.2.cv2.conv.weight\", \"model.model.2.cv2.bn.weight\", \"model.model.2.cv2.bn.bias\", \"model.model.2.cv2.bn.running_mean\", \"model.model.2.cv2.bn.running_var\", \"model.model.2.cv3.conv.weight\", \"model.model.2.cv3.bn.weight\", \"model.model.2.cv3.bn.bias\", \"model.model.2.cv3.bn.running_mean\", \"model.model.2.cv3.bn.running_var\", \"model.model.2.m.0.cv1.conv.weight\", \"model.model.2.m.0.cv1.bn.weight\", \"model.model.2.m.0.cv1.bn.bias\", \"model.model.2.m.0.cv1.bn.running_mean\", \"model.model.2.m.0.cv1.bn.running_var\", \"model.model.2.m.0.cv2.conv.weight\", \"model.model.2.m.0.cv2.bn.weight\", \"model.model.2.m.0.cv2.bn.bias\", \"model.model.2.m.0.cv2.bn.running_mean\", \"model.model.2.m.0.cv2.bn.running_var\", \"model.model.3.conv.weight\", \"model.model.3.bn.weight\", \"model.model.3.bn.bias\", \"model.model.3.bn.running_mean\", \"model.model.3.bn.running_var\", \"model.model.4.cv1.conv.weight\", \"model.model.4.cv1.bn.weight\", \"model.model.4.cv1.bn.bias\", \"model.model.4.cv1.bn.running_mean\", \"mo...\n\tUnexpected key(s) in state_dict: \"epoch\", \"best_fitness\", \"ema\", \"updates\", \"optimizer\", \"wandb_id\", \"training_results\". "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKgDZsYwye04"
      },
      "source": [
        "### Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DibsDgujye05",
        "outputId": "afa82e1d-a967-4b31-e33e-ae4419d5f604"
      },
      "source": [
        "%cd /content\n",
        "\n",
        "# Delete utils package to reload it (if loaded), because YOLOv3 and YOLOv5 have\n",
        "# the same name for it and it causes error\n",
        "try:\n",
        "  sys.modules.pop('utils')\n",
        "except:\n",
        "  pass\n",
        "\n",
        "# @markdown Model Selection { display-mode: 'form', run: 'auto' }\n",
        "model_name = 'YOLOv5s' # @param ['SSD300 VGG16', 'SSDlite320 MobileNetV3-Large', 'Faster R-CNN ResNet-50 FPN', 'Faster R-CNN MobileNetV3-Large FPN', 'Mask R-CNN ResNet-50 FPN', 'YOLOv5s', 'YOLOv5m', 'YOLOv5l', 'YOLOv3', 'YOLOv3-tiny', 'YOLOv3-spp']\n",
        "\n",
        "# @markdown *Note: If you get the error \"Cache may be out of date, try 'force_reload=True'\" then restart runtime.*\n",
        "\n",
        "num_classes = len(val_dataset.coco.getCatIds())\n",
        "\n",
        "if model_name == 'SSD300 VGG16':\n",
        "  model_id = 'ssd300_vgg16'\n",
        "  model = M.ssd300_vgg16(pretrained=False, progress=True)\n",
        "  model_img_size = (3,300,300)\n",
        "elif model_name == 'SSDlite320 MobileNetV3-Large':\n",
        "  model_id = 'ssdlite320_mobilenet_v3_large'\n",
        "  model = M.ssdlite320_mobilenet_v3_large(pretrained=False, progress=True)\n",
        "  model_img_size = (3,320,320)\n",
        "elif model_name == 'Faster R-CNN ResNet-50 FPN':\n",
        "  model_id = 'fasterrcnn_resnet50_fpn'\n",
        "  model = M.fasterrcnn_resnet50_fpn(pretrained=False, progress=True)\n",
        "  model_img_size = (3,800,800) # COCO's 640x640 in upscaled to the model's minimum 800x800\n",
        "elif model_name == 'Faster R-CNN MobileNetV3-Large FPN':\n",
        "  model_id = 'fasterrcnn_mobilenet_v3_large_fpn'\n",
        "  model = M.fasterrcnn_mobilenet_v3_large_fpn(pretrained=False, progress=True)\n",
        "  model_img_size = (3,800,800) \n",
        "elif model_name == 'Mask R-CNN ResNet-50 FPN':\n",
        "  model_id = 'maskrcnn_resnet50_fpn'\n",
        "  model = M.maskrcnn_resnet50_fpn(pretrained=False, progress=True)\n",
        "  model_img_size = (3,800,800)\n",
        "elif 'YOLOv5' in model_name:\n",
        "  model_id = model_name.lower().replace('-','_')\n",
        "  model = torch.hub.load('/content/yolov5', 'custom', path=load_ckpt_path, source='local', force_reload=True)\n",
        "  model_img_size = (3,640,640)\n",
        "elif 'YOLOv3' in model_name:\n",
        "  model_id = model_name.lower().replace('-','_')\n",
        "  model = torch.hub.load('/content/yolov3', 'custom', path=load_ckpt_path, source='local', force_reload=True)\n",
        "  model_img_size = (3,640,640)\n",
        "\n",
        "# Prepare model for dataset (for Fast R-CNN or Mask R-CNN)\n",
        "if 'R-CNN' in model_name: \n",
        "  # Get the number of input features for the bbox predictor\n",
        "  in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "  # Replace the pre-trained head with a new one\n",
        "  model.roi_heads.box_predictor = M.faster_rcnn.FastRCNNPredictor(in_features, num_classes+1)  # includes background (0) class\n",
        "  if 'Mask R-CNN' in model_name:\n",
        "    # Get the number of input features for the segmentation max predictor\n",
        "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "    hidden_layer = 256\n",
        "    # Replace the mask predictor with a new one\n",
        "    model.roi_heads.mask_predictor = M.mask_rcnn.MaskRCNNPredictor(in_features_mask, hidden_layer,num_classes+1)\n",
        "\n",
        "print('-------------------------------------------------------------------------------------------------------\\n')\n",
        "\n",
        "print(f'Loaded model: {model_name}')\n",
        "model_params = round(sum([param.numel() for param in model.parameters()]) / 1000000, 1)\n",
        "print(f'\\t- Parameters: {model_params}M')\n",
        "model_macs, _ = get_model_complexity_info(model, model_img_size, as_strings=False, \n",
        "                                          print_per_layer_stat=False, verbose=False)\n",
        "model_gflops = round(2 * int(model_macs) / 1000000000, 1)\n",
        "print(f'\\t- GFLOPs: {model_gflops}')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 2021-9-13 torch 1.9.0+cu102 CPU\n",
            "\n",
            "Fusing layers... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model Summary: 224 layers, 7059304 parameters, 0 gradients, 16.3 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------------------------------------------\n",
            "\n",
            "Loaded model: YOLOv5s\n",
            "\t- Parameters: 7.1M\n",
            "\t- GFLOPs: 16.3\n"
          ]
        }
      ]
    }
  ]
}