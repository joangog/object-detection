{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "coco2017_inference.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "l9IQxr2jWaui",
        "kFpoV3E0-smW"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joangog/object-detection/blob/main/coco2017_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIjcsMslUx9m"
      },
      "source": [
        "## Model comparison on COCO 2017 dataset\n",
        "*   SSD300 VGG16\n",
        "*   Faster R-CNN ResNet-50 FPN\n",
        "*   Mask R-CNN ResNet-50 FPN\n",
        "*   YOLOv5s\n",
        "*   YOLOv5m\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9IQxr2jWaui"
      },
      "source": [
        "### Get requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-XSXNc61vV3"
      },
      "source": [
        "%%shell\n",
        "\n",
        "# Install Yolov5\n",
        "cd /content\n",
        "git clone https://github.com/ultralytics/yolov5\n",
        "cd yolov5\n",
        "pip install --quiet -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gWOqjlQQdaP"
      },
      "source": [
        "%%shell\n",
        "\n",
        "# Clone torchvision repository and get aux files\n",
        "cd /content\n",
        "git clone https://github.com/pytorch/vision.git\n",
        "cd vision\n",
        "cp references/detection/utils.py ../\n",
        "cp references/detection/transforms.py ../\n",
        "cp references/detection/coco_eval.py ../\n",
        "cp references/detection/coco_utils.py ../"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp4s5Q5fdG_x"
      },
      "source": [
        "### Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eZg3dOcWfsV"
      },
      "source": [
        "# Import packages\n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "import math\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "import json\n",
        "import cv2\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection import ssd300_vgg16, fasterrcnn_resnet50_fpn, maskrcnn_resnet50_fpn\n",
        "from torchvision.datasets import CocoDetection\n",
        "from torchvision.transforms import Compose, Resize, ToTensor\n",
        "\n",
        "import utils\n",
        "from utils import collate_fn\n",
        "from coco_utils import get_coco_api_from_dataset\n",
        "from coco_eval import CocoEvaluator"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ-lfNPQlcuO"
      },
      "source": [
        "### Define aux functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31FW_LJclb-P"
      },
      "source": [
        "# Copied from repo vision/references/detection/engine.py\n",
        "def _get_iou_types(model):\n",
        "    model_without_ddp = model\n",
        "    if isinstance(model, torch.nn.parallel.DistributedDataParallel):\n",
        "        model_without_ddp = model.module\n",
        "    iou_types = [\"bbox\"]\n",
        "    if isinstance(model_without_ddp, torchvision.models.detection.MaskRCNN):\n",
        "        iou_types.append(\"segm\")\n",
        "    if isinstance(model_without_ddp, torchvision.models.detection.KeypointRCNN):\n",
        "        iou_types.append(\"keypoints\")\n",
        "    return iou_types\n",
        "\n",
        "# Copied from repo vision/references/detection/engine.py with adjustments\n",
        "@torch.no_grad()\n",
        "def evaluate(model, data_loader, device):\n",
        "    n_threads = torch.get_num_threads()\n",
        "    torch.set_num_threads(1)\n",
        "    cpu_device = torch.device(\"cpu\")\n",
        "    model.eval()\n",
        "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
        "    header = 'Test:'\n",
        "\n",
        "    coco = get_coco_api_from_dataset(data_loader.dataset)\n",
        "    iou_types = _get_iou_types(model)\n",
        "    coco_evaluator = CocoEvaluator(coco, iou_types)\n",
        "\n",
        "    for images, targets in metric_logger.log_every(data_loader, 100, header):\n",
        "        images = list(img.to(device) for img in images)\n",
        "        targets = [sample for target in targets for sample in target]  # Added this line\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "        model_time = time.time()\n",
        "        outputs = model(images)\n",
        "\n",
        "        outputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\n",
        "        model_time = time.time() - model_time\n",
        "\n",
        "        res = {target[\"image_id\"]: output for target, output in zip(targets, outputs)}\n",
        "        evaluator_time = time.time()\n",
        "        coco_evaluator.update(res)\n",
        "        evaluator_time = time.time() - evaluator_time\n",
        "        metric_logger.update(model_time=model_time, evaluator_time=evaluator_time)\n",
        "\n",
        "    metric_logger.synchronize_between_processes()\n",
        "    print(\"Averaged stats:\", metric_logger)\n",
        "    coco_evaluator.synchronize_between_processes()\n",
        "\n",
        "    coco_evaluator.accumulate()\n",
        "    coco_evaluator.summarize()\n",
        "    torch.set_num_threads(n_threads)\n",
        "    return coco_evaluator\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFpoV3E0-smW"
      },
      "source": [
        "### Download COCO 2017 dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6rHTrcZ1Wle"
      },
      "source": [
        "%%shell\n",
        "\n",
        "# Download images\n",
        "cd /content\n",
        "wget 'http://images.cocodataset.org/zips/val2017.zip'\n",
        "unzip -q 'val2017.zip'\n",
        "rm 'val2017.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIvrZuC_1YK0"
      },
      "source": [
        "%%shell\n",
        "\n",
        "# Download annotations\n",
        "cd /content\n",
        "wget 'http://images.cocodataset.org/annotations/annotations_trainval2017.zip'\n",
        "unzip -q 'annotations_trainval2017.zip'\n",
        "rm 'annotations_trainval2017.zip'\n",
        "cp '/content/annotations/instances_val2017.json' '/content/val2017'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uara-01_5NIB"
      },
      "source": [
        "### Load COCO 2017 dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DC4qQcYh5R88",
        "outputId": "d47c3672-1d35-441a-d445-768149d4d4e8"
      },
      "source": [
        "img_dir = '/content/val2017'\n",
        "ann_file = os.path.join(img_dir,'instances_val2017.json')  # annotations\n",
        "\n",
        "# Define data transforms\n",
        "transforms = Compose([Resize((640,640)), ToTensor()])\n",
        "\n",
        "# Create dataset\n",
        "dataset = CocoDetection(img_dir, ann_file, transform = transforms)\n",
        "\n",
        "# # Create data loader\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "    dataset, batch_size=2, shuffle=False, num_workers=2, collate_fn=collate_fn)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.61s)\n",
            "creating index...\n",
            "index created!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXwGEoyOZfKq"
      },
      "source": [
        "### Load pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVJqPlW8dTvc",
        "cellView": "form",
        "outputId": "e8e5fa3d-7e51-4001-a46c-485afa05488c"
      },
      "source": [
        "# @markdown Model Selection { display-mode: 'form', run: 'auto' }\n",
        "model_name = 'SSD300 VGG16' # @param ['SSD300 VGG16', 'Faster R-CNN ResNet-50 FPN', 'Mask R-CNN ResNet-50 FPN', 'YOLOv5s', 'YOLOv5m']\n",
        "\n",
        "if model_name == 'SSD300 VGG16':\n",
        "  model_id = 'ssd'\n",
        "  model = ssd300_vgg16(pretrained=True, progress=True)\n",
        "elif model_name == 'Faster R-CNN ResNet-50 FPN':\n",
        "  model_id = 'fasterrcnn'\n",
        "  model = fasterrcnn_resnet50_fpn(pretrained=True, progress=True)\n",
        "elif model_name == 'Mask R-CNN ResNet-50 FPN':\n",
        "  model_id = 'maskrcnn'\n",
        "  model = maskrcnn_resnet50_fpn(pretrained=True, progress=True)\n",
        "elif model_name == 'YOLOv5s':\n",
        "  model_id = 'yolov5s'\n",
        "  model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
        "elif model_name == 'YOLOv5m':\n",
        "  model_id = 'yolov5m'\n",
        "  model = torch.hub.load('ultralytics/yolov5', 'yolov5m')\n",
        "\n",
        "print('Loaded model: '+ model_name + '\\n')\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loaded model: SSD300 VGG16\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d4E0DKJ4bOg"
      },
      "source": [
        "### Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BViZf4Ud4Vrp",
        "outputId": "f9e95ced-63a5-40c2-946b-ef37bfb6cca5"
      },
      "source": [
        "# Get appropriate device for model\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Evaluate model\n",
        "evaluate(model, data_loader, device) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Test:  [   0/2500]  eta: 0:18:54  model_time: 0.2524 (0.2524)  evaluator_time: 0.0101 (0.0101)  time: 0.4539  data: 0.1876  max mem: 240\n",
            "Test:  [ 100/2500]  eta: 0:08:18  model_time: 0.1766 (0.1779)  evaluator_time: 0.0130 (0.0205)  time: 0.2010  data: 0.0049  max mem: 240\n",
            "Test:  [ 200/2500]  eta: 0:07:49  model_time: 0.1762 (0.1766)  evaluator_time: 0.0133 (0.0194)  time: 0.1977  data: 0.0039  max mem: 240\n",
            "Test:  [ 300/2500]  eta: 0:07:25  model_time: 0.1751 (0.1760)  evaluator_time: 0.0135 (0.0187)  time: 0.1998  data: 0.0033  max mem: 240\n",
            "Test:  [ 400/2500]  eta: 0:07:05  model_time: 0.1753 (0.1760)  evaluator_time: 0.0108 (0.0192)  time: 0.1974  data: 0.0036  max mem: 240\n",
            "Test:  [ 500/2500]  eta: 0:06:44  model_time: 0.1748 (0.1757)  evaluator_time: 0.0122 (0.0191)  time: 0.1986  data: 0.0040  max mem: 241\n",
            "Test:  [ 600/2500]  eta: 0:06:23  model_time: 0.1745 (0.1755)  evaluator_time: 0.0141 (0.0190)  time: 0.2011  data: 0.0041  max mem: 241\n",
            "Test:  [ 700/2500]  eta: 0:06:04  model_time: 0.1748 (0.1755)  evaluator_time: 0.0172 (0.0196)  time: 0.2203  data: 0.0042  max mem: 241\n",
            "Test:  [ 800/2500]  eta: 0:05:44  model_time: 0.1750 (0.1755)  evaluator_time: 0.0144 (0.0196)  time: 0.1993  data: 0.0037  max mem: 241\n",
            "Test:  [ 900/2500]  eta: 0:05:23  model_time: 0.1726 (0.1755)  evaluator_time: 0.0160 (0.0195)  time: 0.2013  data: 0.0041  max mem: 241\n",
            "Test:  [1000/2500]  eta: 0:05:03  model_time: 0.1747 (0.1755)  evaluator_time: 0.0139 (0.0195)  time: 0.2060  data: 0.0054  max mem: 241\n",
            "Test:  [1100/2500]  eta: 0:04:43  model_time: 0.1749 (0.1754)  evaluator_time: 0.0149 (0.0196)  time: 0.2037  data: 0.0049  max mem: 241\n",
            "Test:  [1200/2500]  eta: 0:04:23  model_time: 0.1764 (0.1754)  evaluator_time: 0.0171 (0.0195)  time: 0.2022  data: 0.0049  max mem: 241\n",
            "Test:  [1300/2500]  eta: 0:04:02  model_time: 0.1738 (0.1755)  evaluator_time: 0.0142 (0.0194)  time: 0.2027  data: 0.0041  max mem: 241\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PhLjHCmTpDS"
      },
      "source": [
        "## Save results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PY3apojFTt2f"
      },
      "source": [
        "results = []\n",
        "for i, img_id in enumerate(img_ids):  # For every image\n",
        "  img_predictions = predictions[i]\n",
        "  pred_boxes = img_predictions['boxes'].tolist()\n",
        "  pred_labels = img_predictions['labels'].tolist()\n",
        "  pred_scores = img_predictions['scores'].tolist()\n",
        "  for j in range(0,len(pred_box)):  # For every predicted object\n",
        "    pred_box = pred_boxes[j]\n",
        "    results.append({\n",
        "        'image_id': img_id,\n",
        "        'category_id': pred_labels[j],\n",
        "        'bbox': [round(val,1) for val in pred_box],  # Round for lower file size\n",
        "        'score': pred_scores[j]\n",
        "        })\n",
        "\n",
        "results_file = os.path.join(img_dir,f'{model_id}_coco17_results.json')\n",
        "with open(results_file, 'w') as outfile: \n",
        "    json.dump(results, outfile,indent = 2)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "y7eEGk6qj2D4",
        "outputId": "4055676b-f257-46e0-aa26-2bb37baaef2f"
      },
      "source": [
        "files.download(results_file) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_036e8f50-f626-49a5-ae78-0da65a1dd820\", \"fasterrcnn_coco17_results.json\", 820)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tsk8d7xeS-MR"
      },
      "source": [
        "# results_dataset = dataset.loadRes(results_file)\n",
        "# eval = cocoeval.COCOeval(dataset, results_dataset, iouType='bbox')\n",
        "# eval.evaluate()\n",
        "# eval.accumulate()\n",
        "# eval.summarize()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}