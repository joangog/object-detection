{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "coco2017_inference.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Lp4s5Q5fdG_x",
        "kFpoV3E0-smW",
        "Uara-01_5NIB",
        "uEmfFmE6cl7U",
        "zPcMtX-sxDW7",
        "-PhLjHCmTpDS",
        "N4gtutCucXKQ"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joangog/object-detection/blob/main/coco2017_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIjcsMslUx9m"
      },
      "source": [
        "## Model evaluation (inference) on COCO 2017 dataset\n",
        "\n",
        "The following models will be evaluated:\n",
        "\n",
        "| Model | Backbone | Image Size | Parameters | GFLOPs\n",
        "| --- | --- | --- | --- | --- |\n",
        "| SSDlite320 | MobileNetV3-Large | 320x320 | 3.4M | 1.2 |\n",
        "| SSD300 | VGG16 | 300x300 | 35.6M | 69.8 |\n",
        "| Faster R-CNN |  MobileNetV3-Large FPN | 800x800 | 19.4M | 9.1 |\n",
        "| Faster R-CNN |  ResNet-50 FPN | 800x800 | 41.8M | 269.1 |\n",
        "| Mask R-CNN |  ResNet-50 FPN | 800x800 | 44.4M | 269.1 |\n",
        "| YOLOv5s |  Custom | 640x640 | 7.3M | 17 |\n",
        "| YOLOv5m |  Custom | 640x640 | 21.4M | 51.3 |\n",
        "| YOLOv5l |  Custom |640x640 | 47M | 115.5 |\n",
        "| YOLOv3-tiny |  Darknet53 | 640x640 | 8.8M | 13.3 |\n",
        "| YOLOv3 |  Darknet53 | 640x640 | 61.9M | 156.3 |\n",
        "| YOLOv3-spp |  Darknet53 | 640x640 | 63M | 157.1 |\n",
        "\n",
        "<br>\n",
        "\n",
        "**Note: GPU Runtime needed (hosted or local)**\n",
        "\n",
        "*Example experiment: Tesla K80, 460.32.03, 11441 MiB, batch_size=8 (or 1), workers=2*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4X0kW-fHdG9R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "752fb24f-30fc-45be-8b02-4912b9189551"
      },
      "source": [
        "# Show system specs\n",
        "!nvidia-smi --query-gpu=gpu_name,driver_version,memory.total --format=csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name, driver_version, memory.total [MiB]\r\n",
            "NVIDIA GeForce GTX 960, 465.19.01, 4036 MiB\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVojvH9i8ua0"
      },
      "source": [
        "### Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZHe4nxx8raL"
      },
      "source": [
        "# Parameters\n",
        "\n",
        "img_size = 160  # Image resolution (for YOLO models), try 640, 320 or 160\n",
        "num_workers = 2  #  Data loader workers\n",
        "batch_size = 1  # Data loader batch size\n",
        "\n",
        "th = 0.5  # Threshold for confidence score of predicted bboxes to show\n",
        "\n",
        "# Directories\n",
        "\n",
        "import os\n",
        "root_dir = os.getcwd()  # Root dir of project\n",
        "dataset_dir = os.path.join(root_dir,'dataset_COCO17')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9IQxr2jWaui"
      },
      "source": [
        "### Get requirements\n",
        "*Note: Restart runtime after installation*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gWOqjlQQdaP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51666dc1-d1b4-40b7-d6df-9793cbb7fbc1"
      },
      "source": [
        "# Clone asset files\n",
        "!cd {root_dir}\n",
        "!git clone https://github.com/joangog/object-detection-assets\n",
        "!mv -n {os.path.join(root_dir,'object-detection-assets','scripts')} ./\n",
        "!mv -n {os.path.join(root_dir,'object-detection-assets','requirements.txt')} ./\n",
        "!rm -rf {os.path.join(root_dir,'object-detection-assets')}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'object-detection-assets'...\n",
            "remote: Enumerating objects: 151, done.\u001b[K\n",
            "remote: Counting objects: 100% (151/151), done.\u001b[K\n",
            "remote: Compressing objects: 100% (113/113), done.\u001b[K\n",
            "remote: Total 151 (delta 51), reused 124 (delta 27), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (151/151), 33.15 KiB | 1.04 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVa0AxzKlSyv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f66b111a-4baa-4b58-9561-bd2f06142351"
      },
      "source": [
        "# Install packages\n",
        "!cd {root_dir}\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/googlecolab/colabtools.git (from -r requirements.txt (line 19))\r\n",
            "  Cloning https://github.com/googlecolab/colabtools.git to /tmp/pip-req-build-5h7d9jyd\r\n",
            "  Running command git clone --filter=blob:none -q https://github.com/googlecolab/colabtools.git /tmp/pip-req-build-5h7d9jyd\n",
            "  Resolved https://github.com/googlecolab/colabtools.git to commit 9a3ffe8ca40ea24a8dc9d80157b0fba5ae48b9d1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25hRequirement already satisfied: gdown in ./object-detection-venv/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (3.6.4)\n",
            "Requirement already satisfied: numpy in ./object-detection-venv/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (1.19.5)\n",
            "Requirement already satisfied: pandas in ./object-detection-venv/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (1.1.5)\n",
            "Requirement already satisfied: IPython in ./object-detection-venv/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (5.5.0)\n",
            "Requirement already satisfied: textwrap3 in ./object-detection-venv/lib/python3.7/site-packages (from -r requirements.txt (line 6)) (0.9.2)\n",
            "Requirement already satisfied: matplotlib in ./object-detection-venv/lib/python3.7/site-packages (from -r requirements.txt (line 8)) (3.2.2)\n",
            "Requirement already satisfied: torch in ./object-detection-venv/lib/python3.7/site-packages (from -r requirements.txt (line 10)) (1.9.0)\n",
            "Requirement already satisfied: torchvision in ./object-detection-venv/lib/python3.7/site-packages (from -r requirements.txt (line 11)) (0.10.0)\n",
            "Requirement already satisfied: pycocotools in ./object-detection-venv/lib/python3.7/site-packages (from -r requirements.txt (line 13)) (2.0.2)\n",
            "Requirement already satisfied: ptflops in ./object-detection-venv/lib/python3.7/site-packages (from -r requirements.txt (line 15)) (0.6.6)\n",
            "Requirement already satisfied: Js2Py in ./object-detection-venv/lib/python3.7/site-packages (from -r requirements.txt (line 17)) (0.71)\n",
            "Requirement already satisfied: pip~=21.3.1 in ./object-detection-venv/lib/python3.7/site-packages (from -r requirements.txt (line 22)) (21.3.1)\n",
            "Requirement already satisfied: setuptools~=58.5.2 in ./object-detection-venv/lib/python3.7/site-packages (from -r requirements.txt (line 23)) (58.5.3)\n",
            "Requirement already satisfied: tqdm in ./object-detection-venv/lib/python3.7/site-packages (from gdown->-r requirements.txt (line 1)) (4.62.3)\n",
            "Requirement already satisfied: requests in ./object-detection-venv/lib/python3.7/site-packages (from gdown->-r requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: six in ./object-detection-venv/lib/python3.7/site-packages (from gdown->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in ./object-detection-venv/lib/python3.7/site-packages (from pandas->-r requirements.txt (line 4)) (2021.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in ./object-detection-venv/lib/python3.7/site-packages (from pandas->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in ./object-detection-venv/lib/python3.7/site-packages (from IPython->-r requirements.txt (line 5)) (5.1.0)\n",
            "Requirement already satisfied: pickleshare in ./object-detection-venv/lib/python3.7/site-packages (from IPython->-r requirements.txt (line 5)) (0.7.5)\n",
            "Requirement already satisfied: pygments in ./object-detection-venv/lib/python3.7/site-packages (from IPython->-r requirements.txt (line 5)) (2.10.0)\n",
            "Requirement already satisfied: decorator in ./object-detection-venv/lib/python3.7/site-packages (from IPython->-r requirements.txt (line 5)) (5.1.0)\n",
            "Requirement already satisfied: pexpect in ./object-detection-venv/lib/python3.7/site-packages (from IPython->-r requirements.txt (line 5)) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in ./object-detection-venv/lib/python3.7/site-packages (from IPython->-r requirements.txt (line 5)) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in ./object-detection-venv/lib/python3.7/site-packages (from IPython->-r requirements.txt (line 5)) (1.0.18)\n",
            "Requirement already satisfied: cycler>=0.10 in ./object-detection-venv/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 8)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in ./object-detection-venv/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 8)) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in ./object-detection-venv/lib/python3.7/site-packages (from matplotlib->-r requirements.txt (line 8)) (1.3.2)\n",
            "Requirement already satisfied: typing-extensions in ./object-detection-venv/lib/python3.7/site-packages (from torch->-r requirements.txt (line 10)) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=5.3.0 in ./object-detection-venv/lib/python3.7/site-packages (from torchvision->-r requirements.txt (line 11)) (7.1.2)\n",
            "Requirement already satisfied: cython>=0.27.3 in ./object-detection-venv/lib/python3.7/site-packages (from pycocotools->-r requirements.txt (line 13)) (0.29.24)\n",
            "Requirement already satisfied: pyjsparser>=2.5.1 in ./object-detection-venv/lib/python3.7/site-packages (from Js2Py->-r requirements.txt (line 17)) (2.7.1)\n",
            "Requirement already satisfied: tzlocal>=1.2 in ./object-detection-venv/lib/python3.7/site-packages (from Js2Py->-r requirements.txt (line 17)) (3.0)\n",
            "Requirement already satisfied: astor~=0.8.1 in ./object-detection-venv/lib/python3.7/site-packages (from google-colab==1.0.0->-r requirements.txt (line 19)) (0.8.1)\n",
            "Requirement already satisfied: google-auth>=1.17.2 in ./object-detection-venv/lib/python3.7/site-packages (from google-colab==1.0.0->-r requirements.txt (line 19)) (1.35.0)\n",
            "Requirement already satisfied: ipykernel~=4.10 in ./object-detection-venv/lib/python3.7/site-packages (from google-colab==1.0.0->-r requirements.txt (line 19)) (4.10.1)\n",
            "Requirement already satisfied: portpicker~=1.3.1 in ./object-detection-venv/lib/python3.7/site-packages (from google-colab==1.0.0->-r requirements.txt (line 19)) (1.3.9)\n",
            "Requirement already satisfied: notebook~=5.3.0 in ./object-detection-venv/lib/python3.7/site-packages (from google-colab==1.0.0->-r requirements.txt (line 19)) (5.3.1)\n",
            "Requirement already satisfied: tornado~=5.1.0 in ./object-detection-venv/lib/python3.7/site-packages (from google-colab==1.0.0->-r requirements.txt (line 19)) (5.1.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in ./object-detection-venv/lib/python3.7/site-packages (from google-auth>=1.17.2->google-colab==1.0.0->-r requirements.txt (line 19)) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in ./object-detection-venv/lib/python3.7/site-packages (from google-auth>=1.17.2->google-colab==1.0.0->-r requirements.txt (line 19)) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./object-detection-venv/lib/python3.7/site-packages (from google-auth>=1.17.2->google-colab==1.0.0->-r requirements.txt (line 19)) (0.2.8)\n",
            "Requirement already satisfied: jupyter-client in ./object-detection-venv/lib/python3.7/site-packages (from ipykernel~=4.10->google-colab==1.0.0->-r requirements.txt (line 19)) (7.0.6)\n",
            "Requirement already satisfied: terminado>=0.8.1 in ./object-detection-venv/lib/python3.7/site-packages (from notebook~=5.3.0->google-colab==1.0.0->-r requirements.txt (line 19)) (0.12.1)\n",
            "Requirement already satisfied: nbformat in ./object-detection-venv/lib/python3.7/site-packages (from notebook~=5.3.0->google-colab==1.0.0->-r requirements.txt (line 19)) (5.1.3)\n",
            "Requirement already satisfied: jinja2 in ./object-detection-venv/lib/python3.7/site-packages (from notebook~=5.3.0->google-colab==1.0.0->-r requirements.txt (line 19)) (3.0.2)\n",
            "Requirement already satisfied: ipython-genutils in ./object-detection-venv/lib/python3.7/site-packages (from notebook~=5.3.0->google-colab==1.0.0->-r requirements.txt (line 19)) (0.2.0)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in ./object-detection-venv/lib/python3.7/site-packages (from notebook~=5.3.0->google-colab==1.0.0->-r requirements.txt (line 19)) (4.8.1)\n",
            "Requirement already satisfied: nbconvert in ./object-detection-venv/lib/python3.7/site-packages (from notebook~=5.3.0->google-colab==1.0.0->-r requirements.txt (line 19)) (6.2.0)\n",
            "Requirement already satisfied: Send2Trash in ./object-detection-venv/lib/python3.7/site-packages (from notebook~=5.3.0->google-colab==1.0.0->-r requirements.txt (line 19)) (1.8.0)\n",
            "Requirement already satisfied: wcwidth in ./object-detection-venv/lib/python3.7/site-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->-r requirements.txt (line 5)) (0.2.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in ./object-detection-venv/lib/python3.7/site-packages (from requests->gdown->-r requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./object-detection-venv/lib/python3.7/site-packages (from requests->gdown->-r requirements.txt (line 1)) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./object-detection-venv/lib/python3.7/site-packages (from requests->gdown->-r requirements.txt (line 1)) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in ./object-detection-venv/lib/python3.7/site-packages (from requests->gdown->-r requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: backports.zoneinfo in ./object-detection-venv/lib/python3.7/site-packages (from tzlocal>=1.2->Js2Py->-r requirements.txt (line 17)) (0.2.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in ./object-detection-venv/lib/python3.7/site-packages (from pexpect->IPython->-r requirements.txt (line 5)) (0.7.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in ./object-detection-venv/lib/python3.7/site-packages (from jupyter-client->ipykernel~=4.10->google-colab==1.0.0->-r requirements.txt (line 19)) (1.5.1)\n",
            "Requirement already satisfied: entrypoints in ./object-detection-venv/lib/python3.7/site-packages (from jupyter-client->ipykernel~=4.10->google-colab==1.0.0->-r requirements.txt (line 19)) (0.3)\n",
            "Requirement already satisfied: pyzmq>=13 in ./object-detection-venv/lib/python3.7/site-packages (from jupyter-client->ipykernel~=4.10->google-colab==1.0.0->-r requirements.txt (line 19)) (22.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./object-detection-venv/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.17.2->google-colab==1.0.0->-r requirements.txt (line 19)) (0.4.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./object-detection-venv/lib/python3.7/site-packages (from jinja2->notebook~=5.3.0->google-colab==1.0.0->-r requirements.txt (line 19)) (2.0.1)\n",
            "Requirement already satisfied: testpath in ./object-detection-venv/lib/python3.7/site-packages (from nbconvert->notebook~=5.3.0->google-colab==1.0.0->-r requirements.txt (line 19)) (0.5.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in ./object-detection-venv/lib/python3.7/site-packages (from nbconvert->notebook~=5.3.0->google-colab==1.0.0->-r requirements.txt (line 19)) (0.8.4)\n",
            "Requirement already satisfied: bleach in ./object-detection-venv/lib/python3.7/site-packages (from nbconvert->notebook~=5.3.0->google-colab==1.0.0->-r requirements.txt (line 19)) (4.1.0)\n",
            "Requirement already satisfied: defusedxml in ./object-detection-venv/lib/python3.7/site-packages (from nbconvert->notebook~=5.3.0->google-colab==1.0.0->-r requirements.txt (line 19)) (0.7.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in ./object-detection-venv/lib/python3.7/site-packages (from nbconvert->notebook~=5.3.0->google-colab==1.0.0->-r requirements.txt (line 19)) (1.5.0)\n",
            "Requirement already satisfied: jupyterlab-pygments in ./object-detection-venv/lib/python3.7/site-packages (from nbconvert->notebook~=5.3.0->google-colab==1.0.0->-r requirements.txt (line 19)) (0.1.2)\n",
            "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in ./object-detection-venv/lib/python3.7/site-packages (from nbconvert->notebook~=5.3.0->google-colab==1.0.0->-r requirements.txt (line 19)) (0.5.4)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in ./object-detection-venv/lib/python3.7/site-packages (from nbformat->notebook~=5.3.0->google-colab==1.0.0->-r requirements.txt (line 19)) (4.1.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in ./object-detection-venv/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook~=5.3.0->google-colab==1.0.0->-r requirements.txt (line 19)) (21.2.0)\n",
            "Requirement already satisfied: importlib-metadata in ./object-detection-venv/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook~=5.3.0->google-colab==1.0.0->-r requirements.txt (line 19)) (4.8.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in ./object-detection-venv/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook~=5.3.0->google-colab==1.0.0->-r requirements.txt (line 19)) (0.18.0)\n",
            "Requirement already satisfied: packaging in ./object-detection-venv/lib/python3.7/site-packages (from bleach->nbconvert->notebook~=5.3.0->google-colab==1.0.0->-r requirements.txt (line 19)) (21.0)\n",
            "Requirement already satisfied: webencodings in ./object-detection-venv/lib/python3.7/site-packages (from bleach->nbconvert->notebook~=5.3.0->google-colab==1.0.0->-r requirements.txt (line 19)) (0.5.1)\n",
            "Requirement already satisfied: zipp>=0.5 in ./object-detection-venv/lib/python3.7/site-packages (from importlib-metadata->jsonschema!=2.5.0,>=2.4->nbformat->notebook~=5.3.0->google-colab==1.0.0->-r requirements.txt (line 19)) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-XSXNc61vV3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a4833ea-4c9f-4c81-d3fa-9e76bb47acc4"
      },
      "source": [
        "# Install Yolov5\n",
        "!cd {root_dir}\n",
        "!git clone https://github.com/joangog/yolov5\n",
        "!pip install -r {os.path.join(root_dir,'yolov5','requirements.txt')}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'yolov5' already exists and is not an empty directory.\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in ./object-detection-venv/lib/python3.7/site-packages (from -r /home/ioanna/yolov5/requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in ./object-detection-venv/lib/python3.7/site-packages (from -r /home/ioanna/yolov5/requirements.txt (line 5)) (1.19.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in ./object-detection-venv/lib/python3.7/site-packages (from -r /home/ioanna/yolov5/requirements.txt (line 6)) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in ./object-detection-venv/lib/python3.7/site-packages (from -r /home/ioanna/yolov5/requirements.txt (line 7)) (7.1.2)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in ./object-detection-venv/lib/python3.7/site-packages (from -r /home/ioanna/yolov5/requirements.txt (line 8)) (5.4.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in ./object-detection-venv/lib/python3.7/site-packages (from -r /home/ioanna/yolov5/requirements.txt (line 9)) (2.23.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in ./object-detection-venv/lib/python3.7/site-packages (from -r /home/ioanna/yolov5/requirements.txt (line 10)) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in ./object-detection-venv/lib/python3.7/site-packages (from -r /home/ioanna/yolov5/requirements.txt (line 11)) (1.9.0)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in ./object-detection-venv/lib/python3.7/site-packages (from -r /home/ioanna/yolov5/requirements.txt (line 12)) (0.10.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in ./object-detection-venv/lib/python3.7/site-packages (from -r /home/ioanna/yolov5/requirements.txt (line 13)) (4.62.3)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in ./object-detection-venv/lib/python3.7/site-packages (from -r /home/ioanna/yolov5/requirements.txt (line 16)) (2.6.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in ./object-detection-venv/lib/python3.7/site-packages (from -r /home/ioanna/yolov5/requirements.txt (line 20)) (1.1.5)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in ./object-detection-venv/lib/python3.7/site-packages (from -r /home/ioanna/yolov5/requirements.txt (line 21)) (0.11.2)\n",
            "Requirement already satisfied: thop in ./object-detection-venv/lib/python3.7/site-packages (from -r /home/ioanna/yolov5/requirements.txt (line 36)) (0.0.31.post2005241907)\n",
            "Requirement already satisfied: pip~=21.3.1 in ./object-detection-venv/lib/python3.7/site-packages (from -r /home/ioanna/yolov5/requirements.txt (line 38)) (21.3.1)\n",
            "Requirement already satisfied: setuptools~=58.5.2 in ./object-detection-venv/lib/python3.7/site-packages (from -r /home/ioanna/yolov5/requirements.txt (line 39)) (58.5.3)\n",
            "Requirement already satisfied: cycler>=0.10 in ./object-detection-venv/lib/python3.7/site-packages (from matplotlib>=3.2.2->-r /home/ioanna/yolov5/requirements.txt (line 4)) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in ./object-detection-venv/lib/python3.7/site-packages (from matplotlib>=3.2.2->-r /home/ioanna/yolov5/requirements.txt (line 4)) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in ./object-detection-venv/lib/python3.7/site-packages (from matplotlib>=3.2.2->-r /home/ioanna/yolov5/requirements.txt (line 4)) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in ./object-detection-venv/lib/python3.7/site-packages (from matplotlib>=3.2.2->-r /home/ioanna/yolov5/requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./object-detection-venv/lib/python3.7/site-packages (from requests>=2.23.0->-r /home/ioanna/yolov5/requirements.txt (line 9)) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./object-detection-venv/lib/python3.7/site-packages (from requests>=2.23.0->-r /home/ioanna/yolov5/requirements.txt (line 9)) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in ./object-detection-venv/lib/python3.7/site-packages (from requests>=2.23.0->-r /home/ioanna/yolov5/requirements.txt (line 9)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in ./object-detection-venv/lib/python3.7/site-packages (from requests>=2.23.0->-r /home/ioanna/yolov5/requirements.txt (line 9)) (2.10)\n",
            "Requirement already satisfied: typing-extensions in ./object-detection-venv/lib/python3.7/site-packages (from torch>=1.7.0->-r /home/ioanna/yolov5/requirements.txt (line 11)) (3.7.4.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in ./object-detection-venv/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 16)) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./object-detection-venv/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 16)) (0.4.6)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in ./object-detection-venv/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 16)) (3.18.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in ./object-detection-venv/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 16)) (1.41.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in ./object-detection-venv/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 16)) (2.0.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in ./object-detection-venv/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 16)) (0.14.1)\n",
            "Requirement already satisfied: wheel>=0.26 in ./object-detection-venv/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 16)) (0.37.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in ./object-detection-venv/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 16)) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in ./object-detection-venv/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 16)) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./object-detection-venv/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 16)) (1.8.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in ./object-detection-venv/lib/python3.7/site-packages (from pandas>=1.1.4->-r /home/ioanna/yolov5/requirements.txt (line 20)) (2021.3)\n",
            "Requirement already satisfied: six in ./object-detection-venv/lib/python3.7/site-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 16)) (1.15.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in ./object-detection-venv/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 16)) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in ./object-detection-venv/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 16)) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./object-detection-venv/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 16)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./object-detection-venv/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 16)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in ./object-detection-venv/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 16)) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./object-detection-venv/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 16)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in ./object-detection-venv/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 16)) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in ./object-detection-venv/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=2.4.1->-r /home/ioanna/yolov5/requirements.txt (line 16)) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYO5_FOUR1D_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e824f5ae-4185-4c45-eb3f-3c5a3ee0c754"
      },
      "source": [
        "# Install Yolov3\n",
        "!cd {root_dir}\n",
        "!git clone https://github.com/ultralytics/yolov3\n",
        "!pip install -r {os.path.join(root_dir,'yolov3','requirements.txt')}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'yolov3' already exists and is not an empty directory.\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in ./object-detection-venv/lib/python3.7/site-packages (from -r /home/ioanna/yolov3/requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in ./object-detection-venv/lib/python3.7/site-packages (from -r /home/ioanna/yolov3/requirements.txt (line 5)) (1.19.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in ./object-detection-venv/lib/python3.7/site-packages (from -r /home/ioanna/yolov3/requirements.txt (line 6)) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow in ./object-detection-venv/lib/python3.7/site-packages (from -r /home/ioanna/yolov3/requirements.txt (line 7)) (7.1.2)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in ./object-detection-venv/lib/python3.7/site-packages (from -r /home/ioanna/yolov3/requirements.txt (line 8)) (5.4.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in ./object-detection-venv/lib/python3.7/site-packages (from -r /home/ioanna/yolov3/requirements.txt (line 9)) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in ./object-detection-venv/lib/python3.7/site-packages (from -r /home/ioanna/yolov3/requirements.txt (line 10)) (1.9.0)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in ./object-detection-venv/lib/python3.7/site-packages (from -r /home/ioanna/yolov3/requirements.txt (line 11)) (0.10.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in ./object-detection-venv/lib/python3.7/site-packages (from -r /home/ioanna/yolov3/requirements.txt (line 12)) (4.62.3)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in ./object-detection-venv/lib/python3.7/site-packages (from -r /home/ioanna/yolov3/requirements.txt (line 15)) (2.6.0)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in ./object-detection-venv/lib/python3.7/site-packages (from -r /home/ioanna/yolov3/requirements.txt (line 19)) (0.11.2)\n",
            "Requirement already satisfied: pandas in ./object-detection-venv/lib/python3.7/site-packages (from -r /home/ioanna/yolov3/requirements.txt (line 20)) (1.1.5)\n",
            "Requirement already satisfied: pycocotools>=2.0 in ./object-detection-venv/lib/python3.7/site-packages (from -r /home/ioanna/yolov3/requirements.txt (line 29)) (2.0.2)\n",
            "Requirement already satisfied: thop in ./object-detection-venv/lib/python3.7/site-packages (from -r /home/ioanna/yolov3/requirements.txt (line 30)) (0.0.31.post2005241907)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in ./object-detection-venv/lib/python3.7/site-packages (from matplotlib>=3.2.2->-r /home/ioanna/yolov3/requirements.txt (line 4)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in ./object-detection-venv/lib/python3.7/site-packages (from matplotlib>=3.2.2->-r /home/ioanna/yolov3/requirements.txt (line 4)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in ./object-detection-venv/lib/python3.7/site-packages (from matplotlib>=3.2.2->-r /home/ioanna/yolov3/requirements.txt (line 4)) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in ./object-detection-venv/lib/python3.7/site-packages (from matplotlib>=3.2.2->-r /home/ioanna/yolov3/requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in ./object-detection-venv/lib/python3.7/site-packages (from torch>=1.7.0->-r /home/ioanna/yolov3/requirements.txt (line 10)) (3.7.4.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in ./object-detection-venv/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in ./object-detection-venv/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (58.5.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in ./object-detection-venv/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (2.0.2)\n",
            "Requirement already satisfied: wheel>=0.26 in ./object-detection-venv/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (0.37.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./object-detection-venv/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in ./object-detection-venv/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in ./object-detection-venv/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./object-detection-venv/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (1.8.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in ./object-detection-venv/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (1.41.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in ./object-detection-venv/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (0.14.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in ./object-detection-venv/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (3.18.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in ./object-detection-venv/lib/python3.7/site-packages (from tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (3.3.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in ./object-detection-venv/lib/python3.7/site-packages (from pandas->-r /home/ioanna/yolov3/requirements.txt (line 20)) (2021.3)\n",
            "Requirement already satisfied: cython>=0.27.3 in ./object-detection-venv/lib/python3.7/site-packages (from pycocotools>=2.0->-r /home/ioanna/yolov3/requirements.txt (line 29)) (0.29.24)\n",
            "Requirement already satisfied: six in ./object-detection-venv/lib/python3.7/site-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./object-detection-venv/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in ./object-detection-venv/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in ./object-detection-venv/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./object-detection-venv/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in ./object-detection-venv/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (4.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./object-detection-venv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./object-detection-venv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in ./object-detection-venv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in ./object-detection-venv/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (2.10)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./object-detection-venv/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in ./object-detection-venv/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in ./object-detection-venv/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=2.4.1->-r /home/ioanna/yolov3/requirements.txt (line 15)) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp4s5Q5fdG_x"
      },
      "source": [
        "### Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eZg3dOcWfsV"
      },
      "source": [
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "\n",
        "import gdown\n",
        "\n",
        "import os, sys\n",
        "import math\n",
        "import time\n",
        "import copy\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import PIL\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.models.detection as M\n",
        "import torchvision.transforms.functional as F\n",
        "import torchvision.utils as U\n",
        "from torchvision.datasets import CocoDetection\n",
        "\n",
        "from ptflops import get_model_complexity_info\n",
        "\n",
        "import scripts.utils as SU\n",
        "import scripts.transforms as ST\n",
        "import scripts.engine as SE\n",
        "import scripts.coco_utils as SCU\n",
        "from scripts.coco_eval import CocoEvaluator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoYuEECPX2mQ"
      },
      "source": [
        "### (Optional) Connect to GDrive for storage access\n",
        "*Note: Not possible with local runtime*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gUb3wQZX9R8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c502e26c-6b7f-43f7-b2aa-e4316a730dd3"
      },
      "source": [
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFpoV3E0-smW"
      },
      "source": [
        "### Download COCO 2017 validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGZH-ZSzu6nK"
      },
      "source": [
        "!cd {root_dir}\n",
        "!mkdir -p dataset_COCO17"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6rHTrcZ1Wle",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a819702-d528-463f-ec67-6845bb86d3e0"
      },
      "source": [
        "# Download images\n",
        "!wget -nc http://images.cocodataset.org/zips/val2017.zip\n",
        "!unzip -q -n val2017.zip -d {dataset_dir}\n",
        "\n",
        "!cd {dataset_dir}\n",
        "\n",
        "# Download annotations\n",
        "!wget -nc http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
        "!unzip -q -n annotations_trainval2017.zip -d {dataset_dir}\n",
        "!cp {os.path.join(dataset_dir,'annotations','instances_val2017.json')} {os.path.join(dataset_dir,'val2017')}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File ‘val2017.zip’ already there; not retrieving.\r\n",
            "\n",
            "^C\n",
            "File ‘annotations_trainval2017.zip’ already there; not retrieving.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uara-01_5NIB"
      },
      "source": [
        "### Load COCO 2017 validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC4qQcYh5R88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33281258-ef49-4c87-ed76-5d56b16bb0ee"
      },
      "source": [
        "img_dir = os.path.join(dataset_dir,'val2017')\n",
        "ann_file = 'instances_val2017.json'  # annotations\n",
        "ann_path = os.path.join(img_dir,ann_file)\n",
        "\n",
        "# Define data transforms\n",
        "transforms = ST.Compose([ST.ToTensor()])\n",
        "\n",
        "# Create dataset\n",
        "dataset = CocoDetection(img_dir, ann_path, transforms = transforms)\n",
        "\n",
        "# Create data loader\n",
        "data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, collate_fn=SU.collate_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.48s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEmfFmE6cl7U"
      },
      "source": [
        "### (Optional) Get dataset resolution information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxkvhAL0Stnv"
      },
      "source": [
        "img_ids = dataset.coco.getImgIds()\n",
        "img_x_arr = []\n",
        "img_y_arr = []\n",
        "\n",
        "for img_id in img_ids:\n",
        "  img = PIL.Image.open(os.path.join(img_dir,dataset.coco.loadImgs([img_id])[0]['file_name']))\n",
        "  img_tensor = F.convert_image_dtype(F.to_tensor(img),torch.uint8)\n",
        "  img_shape = img_tensor.shape\n",
        "  img_x_arr.append(img_shape[1])\n",
        "  img_y_arr.append(img_shape[2])\n",
        "\n",
        "img_x_mean = np.mean(img_x_arr)\n",
        "img_y_mean = np.mean(img_y_arr)\n",
        "\n",
        "img_x_max = np.max(img_x_arr)\n",
        "img_y_max = np.max(img_y_arr)\n",
        "\n",
        "print(f'Mean resolution: {img_x_mean,img_y_mean}')\n",
        "print(f'Maximum resolution: {img_x_max,img_y_max}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXwGEoyOZfKq"
      },
      "source": [
        "### Load pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVJqPlW8dTvc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "98b38768-3e25-4c21-a710-0d2b2650ace1"
      },
      "source": [
        "!cd {root_dir}\n",
        "\n",
        "# Empty cache to properly calculate max memory\n",
        "torch.cuda.empty_cache() \n",
        "\n",
        "# Delete utils package to reload it (if loaded), because YOLOv3 and YOLOv5 have\n",
        "# the same name for it and it causes error\n",
        "try:\n",
        "  sys.modules.pop('utils')\n",
        "except:\n",
        "  pass\n",
        "\n",
        "# @markdown Model Selection { display-mode: 'form', run: 'auto' }\n",
        "model_name = 'Faster R-CNN MobileNetV3-Large FPN' # @param ['SSD300 VGG16', 'SSDlite320 MobileNetV3-Large', 'Faster R-CNN ResNet-50 FPN', 'Faster R-CNN MobileNetV3-Large FPN', 'Mask R-CNN ResNet-50 FPN', 'YOLOv5s', 'YOLOv5m', 'YOLOv5l', 'YOLOv3', 'YOLOv3-tiny', 'YOLOv3-spp']\n",
        "\n",
        "# @markdown *Note: If you get the error \"Cache may be out of date, try 'force_reload=True'\" then restart runtime.*\n",
        "\n",
        "if model_name == 'SSD300 VGG16':\n",
        "  model_id = 'ssd300_vgg16'\n",
        "  model = M.ssd300_vgg16(pretrained=True, progress=True)\n",
        "  model_img_size = (3,300,300)\n",
        "elif model_name == 'SSDlite320 MobileNetV3-Large':\n",
        "  model_id = 'ssdlite320_mobilenet_v3_large'\n",
        "  model = M.ssdlite320_mobilenet_v3_large(pretrained=True, progress=True)\n",
        "  model_img_size = (3,320,320)\n",
        "elif model_name == 'Faster R-CNN ResNet-50 FPN':\n",
        "  model_id = 'fasterrcnn_resnet50_fpn'\n",
        "  model = M.fasterrcnn_resnet50_fpn(pretrained=True, progress=True)\n",
        "  model_img_size = (3,800,800) # COCO's 640x640 in upscaled to the model's minimum 800x800\n",
        "elif model_name == 'Faster R-CNN MobileNetV3-Large FPN':\n",
        "  model_id = 'fasterrcnn_mobilenet_v3_large_fpn'\n",
        "  model = M.fasterrcnn_mobilenet_v3_large_fpn(pretrained=True, progress=True)\n",
        "  model_img_size = (3,800,800) \n",
        "elif model_name == 'Mask R-CNN ResNet-50 FPN':\n",
        "  model_id = 'maskrcnn_resnet50_fpn'\n",
        "  model = M.maskrcnn_resnet50_fpn(pretrained=True, progress=True)\n",
        "  model_img_size = (3,800,800)\n",
        "elif model_name == 'YOLOv5s':\n",
        "  model_id = 'yolov5s'\n",
        "  model = torch.hub.load('ultralytics/yolov5', 'yolov5s', force_reload=True)\n",
        "  model_img_size = (3,img_size,img_size)\n",
        "elif model_name == 'YOLOv5m':\n",
        "  model_id = 'yolov5m'\n",
        "  model = torch.hub.load('ultralytics/yolov5', 'yolov5m', force_reload=True)\n",
        "  model_img_size = (3,img_size,img_size)\n",
        "elif model_name == 'YOLOv5l':\n",
        "  model_id = 'yolov5l'\n",
        "  model = torch.hub.load('ultralytics/yolov5', 'yolov5l', force_reload=True)\n",
        "  model_img_size = (3,img_size,img_size)\n",
        "elif model_name == 'YOLOv3':\n",
        "  model_id = 'yolov3'\n",
        "  model = torch.hub.load('ultralytics/yolov3', 'yolov3', force_reload=True)\n",
        "  model_img_size = (3,img_size,img_size)\n",
        "elif model_name == 'YOLOv3-tiny':\n",
        "  model_id = 'yolov3_tiny'\n",
        "  model = torch.hub.load('ultralytics/yolov3', 'yolov3_tiny', force_reload=True)\n",
        "  model_img_size = (3,img_size,img_size)\n",
        "elif model_name == 'YOLOv3-spp':\n",
        "  model_id = 'yolov3_spp'\n",
        "  model = torch.hub.load('ultralytics/yolov3', 'yolov3_spp', force_reload=True)\n",
        "  model_img_size = (3,img_size,img_size)\n",
        "\n",
        "print('-------------------------------------------------------------------------------------------------------\\n')\n",
        "\n",
        "print(f'Loaded model: {model_name}')\n",
        "model_params = round(sum([param.numel() for param in model.parameters()]) / 1000000, 1)\n",
        "print(f'\\t- Parameters: {model_params}M')\n",
        "model_macs, _ = get_model_complexity_info(model, model_img_size, as_strings=False, \n",
        "                                          print_per_layer_stat=False, verbose=False)\n",
        "model_gflops = round(2 * int(model_macs) / 1000000000, 1)\n",
        "print(f'\\t- GFLOPs: {model_gflops}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------------------------------------------\n",
            "\n",
            "Loaded model: Faster R-CNN MobileNetV3-Large FPN\n",
            "\t- Parameters: 19.4M\n",
            "\t- GFLOPs: 9.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/ioanna/object-detection-venv/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPcMtX-sxDW7"
      },
      "source": [
        "### (Optional) Test model with image sample\n",
        "*Note 1: If you get the error \"module 'PIL.TiffTags' has no attribute 'IFD'\" then restart runtime.*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRnDnuP-xC99"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# Parameters\n",
        "img_id = 139\n",
        "\n",
        "# Get appropriate device for model\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Get image sample\n",
        "img = PIL.Image.open(os.path.join(img_dir,dataset.coco.loadImgs([img_id])[0]['file_name']))\n",
        "img_tensor = F.convert_image_dtype(F.to_tensor(img),torch.uint8)\n",
        "img_torchvision = torch.div(img_tensor,255).float().to(device)  # Format image for torchvision models\n",
        "img_anns = dataset.coco.loadAnns(dataset.coco.getAnnIds([img_id]))\n",
        "\n",
        "# Get label names\n",
        "label_ids = dataset.coco.getCatIds()\n",
        "label_info = dataset.coco.loadCats(label_ids)\n",
        "label_names = [label['name'] for label in label_info]\n",
        "labels = dict(zip(label_ids,label_names))  # Label dictionary with id-name as key-value\n",
        "labels_inv = dict(zip(label_names,label_ids))  # Inverse label dictionary with name-id as key-value\n",
        "\n",
        "# Format image\n",
        "img_tensor = F.convert_image_dtype(F.to_tensor(img),torch.uint8)\n",
        "img_torchvision = torch.div(img_tensor,255).float().to(device)  # Format image for torchvision models\n",
        "img_anns = dataset.coco.loadAnns(dataset.coco.getAnnIds([img_id]))\n",
        "\n",
        "# Get ground truth bboxes\n",
        "true_bboxes = SE.convert_to_xyxy(copy.deepcopy(F.Tensor([obj['bbox'] for obj in img_anns]).to(device)))  # Create deep copy to avoid updating original dataset\n",
        "true_labels = [labels[obj['category_id']] for obj in img_anns]\n",
        "true_img = U.draw_bounding_boxes(img_tensor, true_bboxes, true_labels)\n",
        "plt.figure(figsize = (25,7))\n",
        "plt.title('Ground Truth Detection')\n",
        "plot = plt.imshow(F.to_pil_image(true_img))\n",
        "\n",
        "# Generate model predictions\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  if 'YOLO' in model_name:\n",
        "    pred = model([img])\n",
        "  else:    \n",
        "    pred = model([img_torchvision])\n",
        "\n",
        "# Get predicted bboxes\n",
        "# For YOLO models\n",
        "if 'YOLO' in model_name:  \n",
        "  pred_bboxes = []\n",
        "  pred_label_ids = []\n",
        "  pred_labels = []\n",
        "  for bbox in pred.xyxy[0]:  # For every bbox\n",
        "    conf = bbox[4]\n",
        "    if conf > th:  # Show only bboxes with high confidence score\n",
        "      pred_bboxes.append(bbox[:4])\n",
        "      label_id = labels_inv[label_names[int(bbox[5])]]  # Convert YOLO label id to COCO label id\n",
        "      pred_label_ids.append(label_id)  \n",
        "      pred_labels.append(labels[label_id] + f'[{int(conf*100)}%]')\n",
        "  if len(pred_bboxes) != 0:\n",
        "    pred_bboxes = torch.stack(pred_bboxes)\n",
        "\n",
        "# For torchvision models\n",
        "else:\n",
        "  for i, bbox in enumerate(pred[0]['boxes']):  # For every bbox\n",
        "    conf = pred[0]['scores'][i]\n",
        "    if conf > th:  # Show only bboxes with high confidence score\n",
        "      pred_bboxes.append(bbox)\n",
        "      label_id = pred[0]['labels'][i]\n",
        "      pred_label_ids.append(label_id)\n",
        "      pred_labels.append(labels[label_id] + f'[{int(conf*100)}%]')\n",
        "  if len(pred_bboxes) != 0:\n",
        "    pred_bboxes = torch.stack(pred_bboxes)\n",
        "\n",
        "if len(pred_bboxes) != 0:\n",
        "  pred_img = U.draw_bounding_boxes(img_tensor, pred_bboxes, pred_labels)\n",
        "else:  # If no bboxes are found just return the image\n",
        "  pred_img = img_tensor\n",
        "plt.figure(figsize = (25,7))\n",
        "plt.title(f'Predicted Detection (thresh={th})')\n",
        "plot = plt.imshow(F.to_pil_image(pred_img))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d4E0DKJ4bOg"
      },
      "source": [
        "### Evaluate model\n",
        "*Note 1: If you get the error \"module 'PIL.TiffTags' has no attribute 'IFD'\" then restart runtime.*\n",
        "\n",
        "*Note 2: To get accurate maximum GPU memory usage logging, restart runtime when choosing a different model.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BViZf4Ud4Vrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "065015b9-f7db-4a98-c0dd-4789aa367631"
      },
      "source": [
        "# Clear cache for accurate maximum GPU memory usage logging\n",
        "torch.cuda.empty_cache() \n",
        "\n",
        "# Get appropriate device for model\n",
        "device = torch.device('cuda')\n",
        "model.to(device)\n",
        "print(f'Model: {model_name + ( \" (\"  + str(model_img_size[1]) if \"yolo\" in model_id else \"\") + \") \"}')\n",
        "\n",
        "# Evaluate model\n",
        "evaluator, fps, max_mem, outputs = SE.evaluate(model, data_loader, device, img_size=model_img_size[1])\n",
        "\n",
        "print(f'\\nFPS: {fps}\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Faster R-CNN MobileNetV3-Large FPN) \n",
            "Test:  [   0/5000]  eta: 0:16:21  model_time: 0.1056 (0.1056)  evaluator_time: 0.0125 (0.0125)  time: 0.1963  data: 0.0766  max mem: 285\n",
            "Test:  [ 100/5000]  eta: 0:07:34  model_time: 0.0820 (0.0829)  evaluator_time: 0.0060 (0.0070)  time: 0.0917  data: 0.0013  max mem: 305\n",
            "Test:  [ 200/5000]  eta: 0:07:22  model_time: 0.0804 (0.0827)  evaluator_time: 0.0034 (0.0071)  time: 0.0913  data: 0.0012  max mem: 305\n",
            "Test:  [ 300/5000]  eta: 0:07:09  model_time: 0.0837 (0.0824)  evaluator_time: 0.0043 (0.0070)  time: 0.0940  data: 0.0012  max mem: 305\n",
            "Test:  [ 400/5000]  eta: 0:06:58  model_time: 0.0770 (0.0825)  evaluator_time: 0.0037 (0.0069)  time: 0.0823  data: 0.0011  max mem: 305\n",
            "Test:  [ 500/5000]  eta: 0:06:47  model_time: 0.0802 (0.0824)  evaluator_time: 0.0050 (0.0068)  time: 0.0914  data: 0.0012  max mem: 305\n",
            "Test:  [ 600/5000]  eta: 0:06:39  model_time: 0.0796 (0.0824)  evaluator_time: 0.0039 (0.0070)  time: 0.0874  data: 0.0011  max mem: 305\n",
            "Test:  [ 700/5000]  eta: 0:06:30  model_time: 0.0814 (0.0825)  evaluator_time: 0.0036 (0.0070)  time: 0.0893  data: 0.0011  max mem: 305\n",
            "Test:  [ 800/5000]  eta: 0:06:22  model_time: 0.0828 (0.0825)  evaluator_time: 0.0060 (0.0071)  time: 0.0926  data: 0.0011  max mem: 305\n",
            "Test:  [ 900/5000]  eta: 0:06:13  model_time: 0.0813 (0.0825)  evaluator_time: 0.0038 (0.0073)  time: 0.1003  data: 0.0011  max mem: 305\n",
            "Test:  [1000/5000]  eta: 0:06:03  model_time: 0.0792 (0.0824)  evaluator_time: 0.0034 (0.0072)  time: 0.0876  data: 0.0011  max mem: 305\n",
            "Test:  [1100/5000]  eta: 0:05:54  model_time: 0.0823 (0.0824)  evaluator_time: 0.0049 (0.0072)  time: 0.0920  data: 0.0011  max mem: 305\n",
            "Test:  [1200/5000]  eta: 0:05:45  model_time: 0.0847 (0.0825)  evaluator_time: 0.0042 (0.0072)  time: 0.0938  data: 0.0011  max mem: 305\n",
            "Test:  [1300/5000]  eta: 0:05:37  model_time: 0.0812 (0.0826)  evaluator_time: 0.0031 (0.0072)  time: 0.0885  data: 0.0011  max mem: 305\n",
            "Test:  [1400/5000]  eta: 0:05:28  model_time: 0.0842 (0.0825)  evaluator_time: 0.0039 (0.0072)  time: 0.0928  data: 0.0012  max mem: 305\n",
            "Test:  [1500/5000]  eta: 0:05:18  model_time: 0.0793 (0.0824)  evaluator_time: 0.0041 (0.0072)  time: 0.0881  data: 0.0011  max mem: 305\n",
            "Test:  [1600/5000]  eta: 0:05:09  model_time: 0.0855 (0.0825)  evaluator_time: 0.0052 (0.0073)  time: 0.0995  data: 0.0011  max mem: 305\n",
            "Test:  [1700/5000]  eta: 0:05:00  model_time: 0.0791 (0.0824)  evaluator_time: 0.0034 (0.0072)  time: 0.0909  data: 0.0011  max mem: 305\n",
            "Test:  [1800/5000]  eta: 0:04:50  model_time: 0.0799 (0.0823)  evaluator_time: 0.0033 (0.0072)  time: 0.0867  data: 0.0012  max mem: 305\n",
            "Test:  [1900/5000]  eta: 0:04:41  model_time: 0.0790 (0.0823)  evaluator_time: 0.0029 (0.0072)  time: 0.0863  data: 0.0012  max mem: 305\n",
            "Test:  [2000/5000]  eta: 0:04:32  model_time: 0.0804 (0.0824)  evaluator_time: 0.0052 (0.0072)  time: 0.0874  data: 0.0011  max mem: 305\n",
            "Test:  [2100/5000]  eta: 0:04:23  model_time: 0.0828 (0.0823)  evaluator_time: 0.0046 (0.0072)  time: 0.0868  data: 0.0011  max mem: 305\n",
            "Test:  [2200/5000]  eta: 0:04:14  model_time: 0.0790 (0.0822)  evaluator_time: 0.0037 (0.0072)  time: 0.0864  data: 0.0013  max mem: 305\n",
            "Test:  [2300/5000]  eta: 0:04:04  model_time: 0.0757 (0.0822)  evaluator_time: 0.0038 (0.0072)  time: 0.0849  data: 0.0011  max mem: 305\n",
            "Test:  [2400/5000]  eta: 0:03:55  model_time: 0.0854 (0.0822)  evaluator_time: 0.0053 (0.0072)  time: 0.0887  data: 0.0011  max mem: 305\n",
            "Test:  [2500/5000]  eta: 0:03:46  model_time: 0.0781 (0.0822)  evaluator_time: 0.0043 (0.0072)  time: 0.0891  data: 0.0011  max mem: 305\n",
            "Test:  [2600/5000]  eta: 0:03:37  model_time: 0.0775 (0.0821)  evaluator_time: 0.0035 (0.0072)  time: 0.0850  data: 0.0011  max mem: 305\n",
            "Test:  [2700/5000]  eta: 0:03:28  model_time: 0.0794 (0.0821)  evaluator_time: 0.0040 (0.0072)  time: 0.0827  data: 0.0011  max mem: 305\n",
            "Test:  [2800/5000]  eta: 0:03:18  model_time: 0.0836 (0.0821)  evaluator_time: 0.0042 (0.0072)  time: 0.0896  data: 0.0012  max mem: 305\n",
            "Test:  [2900/5000]  eta: 0:03:09  model_time: 0.0809 (0.0821)  evaluator_time: 0.0046 (0.0072)  time: 0.0898  data: 0.0012  max mem: 305\n",
            "Test:  [3000/5000]  eta: 0:03:00  model_time: 0.0795 (0.0820)  evaluator_time: 0.0039 (0.0072)  time: 0.0879  data: 0.0011  max mem: 305\n",
            "Test:  [3100/5000]  eta: 0:02:51  model_time: 0.0789 (0.0819)  evaluator_time: 0.0037 (0.0071)  time: 0.0852  data: 0.0012  max mem: 305\n",
            "Test:  [3200/5000]  eta: 0:02:42  model_time: 0.0779 (0.0818)  evaluator_time: 0.0040 (0.0071)  time: 0.0863  data: 0.0011  max mem: 305\n",
            "Test:  [3300/5000]  eta: 0:02:33  model_time: 0.0789 (0.0818)  evaluator_time: 0.0044 (0.0072)  time: 0.0904  data: 0.0011  max mem: 305\n",
            "Test:  [3400/5000]  eta: 0:02:24  model_time: 0.0778 (0.0817)  evaluator_time: 0.0032 (0.0072)  time: 0.0842  data: 0.0012  max mem: 305\n",
            "Test:  [3500/5000]  eta: 0:02:14  model_time: 0.0746 (0.0817)  evaluator_time: 0.0032 (0.0072)  time: 0.0805  data: 0.0011  max mem: 305\n",
            "Test:  [3600/5000]  eta: 0:02:05  model_time: 0.0805 (0.0816)  evaluator_time: 0.0050 (0.0072)  time: 0.0903  data: 0.0012  max mem: 305\n",
            "Test:  [3700/5000]  eta: 0:01:56  model_time: 0.0822 (0.0816)  evaluator_time: 0.0043 (0.0072)  time: 0.0905  data: 0.0012  max mem: 305\n",
            "Test:  [3800/5000]  eta: 0:01:48  model_time: 0.0834 (0.0816)  evaluator_time: 0.0044 (0.0072)  time: 0.0942  data: 0.0011  max mem: 305\n",
            "Test:  [3900/5000]  eta: 0:01:38  model_time: 0.0768 (0.0815)  evaluator_time: 0.0041 (0.0072)  time: 0.0841  data: 0.0012  max mem: 305\n",
            "Test:  [4000/5000]  eta: 0:01:29  model_time: 0.0762 (0.0815)  evaluator_time: 0.0035 (0.0072)  time: 0.0809  data: 0.0012  max mem: 305\n",
            "Test:  [4100/5000]  eta: 0:01:20  model_time: 0.0842 (0.0815)  evaluator_time: 0.0045 (0.0072)  time: 0.0910  data: 0.0011  max mem: 305\n",
            "Test:  [4200/5000]  eta: 0:01:11  model_time: 0.0781 (0.0814)  evaluator_time: 0.0034 (0.0072)  time: 0.0866  data: 0.0012  max mem: 305\n",
            "Test:  [4300/5000]  eta: 0:01:02  model_time: 0.0833 (0.0814)  evaluator_time: 0.0047 (0.0072)  time: 0.0900  data: 0.0012  max mem: 305\n",
            "Test:  [4400/5000]  eta: 0:00:53  model_time: 0.0829 (0.0814)  evaluator_time: 0.0051 (0.0071)  time: 0.0939  data: 0.0012  max mem: 305\n",
            "Test:  [4500/5000]  eta: 0:00:44  model_time: 0.0839 (0.0813)  evaluator_time: 0.0048 (0.0071)  time: 0.0938  data: 0.0012  max mem: 305\n",
            "Test:  [4600/5000]  eta: 0:00:35  model_time: 0.0788 (0.0813)  evaluator_time: 0.0042 (0.0071)  time: 0.0882  data: 0.0012  max mem: 305\n",
            "Test:  [4700/5000]  eta: 0:00:26  model_time: 0.0830 (0.0813)  evaluator_time: 0.0046 (0.0071)  time: 0.0906  data: 0.0011  max mem: 305\n",
            "Test:  [4800/5000]  eta: 0:00:17  model_time: 0.0819 (0.0812)  evaluator_time: 0.0049 (0.0071)  time: 0.0916  data: 0.0011  max mem: 305\n",
            "Test:  [4900/5000]  eta: 0:00:08  model_time: 0.0837 (0.0812)  evaluator_time: 0.0047 (0.0071)  time: 0.0910  data: 0.0011  max mem: 305\n",
            "Test:  [4999/5000]  eta: 0:00:00  model_time: 0.0774 (0.0812)  evaluator_time: 0.0041 (0.0071)  time: 0.0894  data: 0.0011  max mem: 305\n",
            "Test: Total time: 0:07:27 (0.0894 s / it)\n",
            "Averaged stats: model_time: 0.0774 (0.0812)  evaluator_time: 0.0041 (0.0071)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=4.38s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.328\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.525\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.343\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.127\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.363\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.502\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.287\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.426\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.444\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.196\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.499\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.648\n",
            "\n",
            "FPS: 12.317622540274561\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PhLjHCmTpDS"
      },
      "source": [
        "### Save metric results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8L2RtxdkDVz"
      },
      "source": [
        "cols = ['model', 'model_img_size', 'model_params', 'model_gflops', 'fps', 'max_mem', 'iou_type', 'metric', 'iou', 'area', 'max_dets', 'score']\n",
        "model = []\n",
        "model_img_size_arr = []\n",
        "model_params_arr = []\n",
        "model_gflops_arr = []\n",
        "fps_arr = []\n",
        "max_mem_arr = []\n",
        "iou_type = []\n",
        "metric = []\n",
        "iou = []\n",
        "area = []\n",
        "max_dets = []\n",
        "score = []\n",
        "\n",
        "# Set column values\n",
        "for curr_iou_type, coco_eval in evaluator.coco_eval.items():\n",
        "  model += [model_name for i in range(0,12)]\n",
        "  model_img_size_arr += [model_img_size[1] for i in range(0,12)]\n",
        "  model_params_arr += [model_params for i in range(0,12)]\n",
        "  model_gflops_arr += [model_gflops for i in range(0,12)]\n",
        "  fps_arr += [fps for i in range(0,12)]\n",
        "  max_mem_arr += [max_mem for i in range(0,12)]\n",
        "  iou_type += [curr_iou_type for i in range(0,12)]\n",
        "  metric += ['avg_precision' for i in range(0,6)] + ['avg_recall' for i in range(0,6)]\n",
        "  iou += ['0.50:0.95', '0.50', '0.75'] + ['0.50:0.95' for i in range(0,9)]\n",
        "  area += ['all' for i in range(0,3)] + ['small', 'medium', 'large'] + ['all' for i in range(0,3)] + ['small', 'medium', 'large'] \n",
        "  max_dets += [100 for i in range(0,6)] + [1, 10] + [100 for i in range(0,4)]\n",
        "  score += list(coco_eval.stats)\n",
        "\n",
        "results = pd.DataFrame(np.column_stack([model, model_img_size_arr, model_params_arr, model_gflops_arr, fps_arr, max_mem_arr, iou_type, metric, iou, area, max_dets, score]))\n",
        "results.columns = cols"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhLzrHGOP7AP"
      },
      "source": [
        "# Save to file\n",
        "\n",
        "results_dir = root_dir\n",
        "\n",
        "gpu = torch.cuda.get_device_name(0).lower()\n",
        "for pattern in [' ', 'tesla', 'geforce', 'nvidia']:  # Keep only short gpu name\n",
        "  gpu = gpu.replace(pattern,'')\n",
        "\n",
        "results_file = f'COCO17_{gpu}_{model_id + (\"_\" + str(model_img_size[1]) if \"yolo\" in model_id else \"\")}_metrics.csv'\n",
        "results_path = os.path.join(results_dir, results_file)\n",
        "\n",
        "if os.path.exists(results_path):\n",
        "      os.remove(results_path)\n",
        "results.to_csv(results_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4gtutCucXKQ"
      },
      "source": [
        "### (Optional) Save results to GDrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paaLy2Kzi_xg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e72b653-4215-4858-f28d-af5b054de0e8"
      },
      "source": [
        "# Save to GDrive\n",
        "gdrive_results_dir = '/content/drive/MyDrive/object-detection-results/COCO17'\n",
        "!mkdir gdrive_results_dir\n",
        "gdrive_results_path = os.path.join(gdrive_results_dir, results_file)\n",
        "if os.path.exists(gdrive_results_path):\n",
        "      os.remove(gdrive_results_path)\n",
        "results.to_csv(gdrive_results_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘gdrive_results_dir’: File exists\n"
          ]
        }
      ]
    }
  ]
}